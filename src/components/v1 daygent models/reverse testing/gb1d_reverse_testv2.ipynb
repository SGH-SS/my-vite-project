{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "02EveUOqjWav",
        "outputId": "34e623fa-41d1-4197-f906-0361b188cf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Setting up dependencies...\n",
            "✅ Core dependencies already available\n",
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted (Colab environment)\n",
            "🔄 GB1D Model Reverse Test - Loading and Verifying Saved Model\n",
            "Target: Reproduce EXACT same results as original gb1d_iso.ipynb run\n",
            "Expected test accuracy: 0.7143, test AUC: 0.7733, threshold: 0.57\n",
            "================================================================================\n",
            "✅ Original model directory: /content/drive/MyDrive/daygent_v1_models/gb_1d_versionlock\n",
            "✅ Reverse test output directory: /content/drive/MyDrive/daygent_v1_models/gb_1d_reverse_versionlock\n",
            "✅ Data directory: /content/drive/MyDrive/daygent_v1_models/spy_data_export\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 1: CROSS-PLATFORM DEPENDENCY MANAGEMENT\n",
        "# ========================================\n",
        "print(\"🔧 Setting up dependencies...\")\n",
        "\n",
        "# Cross-platform dependency installation\n",
        "try:\n",
        "    import pandas, numpy, sklearn, xgboost, matplotlib, seaborn, joblib, tqdm\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "    from sklearn.utils.class_weight import compute_sample_weight\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "    import joblib\n",
        "    import lightgbm as lgb  # not used here, keeps env parity\n",
        "    print(\"✅ Core dependencies already available\")\n",
        "except ImportError as e:\n",
        "    print(f\"Installing missing dependencies: {e}\")\n",
        "    import sys, subprocess\n",
        "    pkgs = ['pandas', 'numpy', 'scikit-learn', 'xgboost', 'lightgbm',\n",
        "            'matplotlib', 'seaborn', 'joblib', 'tqdm', 'pyarrow']\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + pkgs)\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "    from sklearn.utils.class_weight import compute_sample_weight\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "    import joblib\n",
        "    print(\"✅ Dependencies installed\")\n",
        "\n",
        "# Try to mount Google Drive if available (Colab environment)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    BASE_DIR = '/content/drive/MyDrive/daygent_v1_models'  # same base folder as your LGBM 4h\n",
        "    print(\"✅ Google Drive mounted (Colab environment)\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    BASE_DIR = './daygent_v1_models'\n",
        "    print(\"✅ Local environment detected\")\n",
        "\n",
        "# Core imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'spy_data_export')\n",
        "ORIGINAL_MODEL_DIR = os.path.join(BASE_DIR, 'gb_1d_versionlock')  # Load from original location\n",
        "REVERSE_MODEL_DIR = os.path.join(BASE_DIR, 'gb_1d_reverse_versionlock')  # Save reverse test results here\n",
        "os.makedirs(REVERSE_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(\"🔄 GB1D Model Reverse Test - Loading and Verifying Saved Model\")\n",
        "print(\"Target: Reproduce EXACT same results as original gb1d_iso.ipynb run\")\n",
        "print(\"Expected test accuracy: 0.7143, test AUC: 0.7733, threshold: 0.57\")\n",
        "print(\"=\"*80)\n",
        "print(f\"✅ Original model directory: {ORIGINAL_MODEL_DIR}\")\n",
        "print(f\"✅ Reverse test output directory: {REVERSE_MODEL_DIR}\")\n",
        "print(f\"✅ Data directory: {DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# VERSION EXTRACTION FOR ENVIRONMENT LOCKING\n",
        "# ========================================\n",
        "print(\"\\n🔒 Extracting exact library versions for environment locking...\")\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "versions = {\n",
        "    'python': sys.version,\n",
        "    'pandas': pd.__version__,\n",
        "    'numpy': np.__version__,\n",
        "    'scikit-learn': sklearn.__version__,\n",
        "    'xgboost': xgb.__version__,\n",
        "    'lightgbm': lgb.__version__,\n",
        "    'joblib': joblib.__version__\n",
        "}\n",
        "\n",
        "print(\"📦 Current library versions:\")\n",
        "for lib, ver in versions.items():\n",
        "    print(f\"  {lib}: {ver}\")\n",
        "\n",
        "# Save versions to file for environment creation\n",
        "versions_file = os.path.join(REVERSE_MODEL_DIR, 'training_versions.json')\n",
        "with open(versions_file, 'w') as f:\n",
        "    json.dump(versions, f, indent=2)\n",
        "\n",
        "print(f\"✅ Versions saved to: {versions_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gOP0zPZ1v39C",
        "outputId": "31b1aa1c-0551-4b28-c1dc-5a4facef580a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔒 Extracting exact library versions for environment locking...\n",
            "📦 Current library versions:\n",
            "  python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "  pandas: 2.2.2\n",
            "  numpy: 2.0.2\n",
            "  scikit-learn: 1.6.1\n",
            "  xgboost: 3.0.4\n",
            "  lightgbm: 4.6.0\n",
            "  joblib: 1.5.1\n",
            "✅ Versions saved to: /content/drive/MyDrive/daygent_v1_models/gb_1d_reverse_versionlock/training_versions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K-ki0UktjWa0",
        "outputId": "01132d42-5c17-4af0-9783-5ebf9267ffe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Loading saved model artifacts...\n",
            "✅ Model loaded: GradientBoostingClassifier\n",
            "✅ Scaler loaded: StandardScaler\n",
            "📊 Feature count: 16\n",
            "🎯 Calibrated threshold: 0.57\n",
            "📅 Original test period: 2024-12-17 to 2025-02-07\n",
            "📋 Original predictions loaded: 35 samples\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 2: LOAD SAVED MODEL ARTIFACTS\n",
        "# ========================================\n",
        "print(\"\\n🔧 Loading saved model artifacts...\")\n",
        "\n",
        "# Load configuration files\n",
        "with open(os.path.join(ORIGINAL_MODEL_DIR, 'results_gb_1d.json'), 'r') as f:\n",
        "    original_results = json.load(f)\n",
        "\n",
        "with open(os.path.join(ORIGINAL_MODEL_DIR, 'deployment_config.json'), 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Load model and scaler\n",
        "model_path = os.path.join(ORIGINAL_MODEL_DIR, 'gb_1d_final.joblib')\n",
        "scaler_path = os.path.join(ORIGINAL_MODEL_DIR, 'scaler_1d.joblib')\n",
        "\n",
        "gb_model = joblib.load(model_path)\n",
        "scaler = joblib.load(scaler_path)\n",
        "\n",
        "# Extract key parameters\n",
        "FEATURE_NAMES = config['feature_names']\n",
        "THRESHOLD = config['calibrated_threshold']\n",
        "TEST_PERIOD = original_results['test_period']\n",
        "\n",
        "print(f\"✅ Model loaded: {type(gb_model).__name__}\")\n",
        "print(f\"✅ Scaler loaded: {type(scaler).__name__}\")\n",
        "print(f\"📊 Feature count: {len(FEATURE_NAMES)}\")\n",
        "print(f\"🎯 Calibrated threshold: {THRESHOLD}\")\n",
        "print(f\"📅 Original test period: {TEST_PERIOD}\")\n",
        "\n",
        "# Load original predictions for comparison\n",
        "original_preds = pd.read_csv(os.path.join(ORIGINAL_MODEL_DIR, 'test_predictions_1d.csv'))\n",
        "print(f\"📋 Original predictions loaded: {len(original_preds)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F0oMnem6jWa1",
        "outputId": "5b3b9a81-2f45-41f9-a067-08a9b9e3b5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Loading raw data (matching original process)...\n",
            "✅ Loaded 1d data: 2,547 candles\n",
            "📅 1d range: 2014-12-23 14:30:00+00:00 to 2025-02-07 14:30:00+00:00\n",
            "✅ Loaded 4h data: 3,058 candles\n",
            "📅 4h range: 2019-01-07 14:30:00+00:00 to 2025-02-10 14:30:00+00:00\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 3: LOAD RAW DATA (EXACT SAME AS ORIGINAL)\n",
        "# ========================================\n",
        "print(\"\\n📊 Loading raw data (matching original process)...\")\n",
        "\n",
        "TIMEFRAMES_ORDERED = ['1d', '4h']\n",
        "raw_data = {}\n",
        "\n",
        "for tf in TIMEFRAMES_ORDERED:\n",
        "    csv_file = os.path.join(DATA_DIR, f'spy_{tf}.csv')\n",
        "    if not os.path.exists(csv_file):\n",
        "        raise FileNotFoundError(f\"❌ {csv_file} not found!\")\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    raw_data[tf] = df\n",
        "    print(f\"✅ Loaded {tf} data: {len(df):,} candles\")\n",
        "    print(f\"📅 {tf} range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F3l3iTzkjWa1",
        "outputId": "db06644d-a118-4654-d6a9-2d306bcc5484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Recreating exact test period determination...\n",
            "📅 Recreated test period: 2024-12-17 → 2025-02-07 (35 trading days)\n",
            "🔍 Original test period: 2024-12-17 to 2025-02-07\n",
            "✅ Test period matches original exactly!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 4: RECREATE EXACT TEST PERIOD (MATCHING ORIGINAL LOGIC)\n",
        "# ========================================\n",
        "print(\"\\n🎯 Recreating exact test period determination...\")\n",
        "\n",
        "# Find common date range between 1d and 4h data\n",
        "latest_start = max(raw_data['1d']['timestamp'].min(), raw_data['4h']['timestamp'].min())\n",
        "earliest_end  = min(raw_data['1d']['timestamp'].max(), raw_data['4h']['timestamp'].max())\n",
        "\n",
        "# Find common trading days\n",
        "common_dates = set(raw_data['1d'][(raw_data['1d']['timestamp'] >= latest_start) &\n",
        "                                  (raw_data['1d']['timestamp'] <= earliest_end)]['timestamp'].dt.date.unique())\n",
        "common_dates &= set(raw_data['4h'][(raw_data['4h']['timestamp'] >= latest_start) &\n",
        "                                   (raw_data['4h']['timestamp'] <= earliest_end)]['timestamp'].dt.date.unique())\n",
        "\n",
        "# Select last 35 days (same as original)\n",
        "all_days = sorted(common_dates)\n",
        "TEST_DAYS = min(35, len(all_days))\n",
        "selected_days = all_days[-TEST_DAYS:]\n",
        "\n",
        "test_start = pd.Timestamp.combine(selected_days[0],  pd.Timestamp.min.time()).tz_localize('UTC')\n",
        "test_end   = pd.Timestamp.combine(selected_days[-1], pd.Timestamp.max.time()).tz_localize('UTC')\n",
        "\n",
        "print(f\"📅 Recreated test period: {test_start.date()} → {test_end.date()} ({TEST_DAYS} trading days)\")\n",
        "print(f\"🔍 Original test period: {TEST_PERIOD}\")\n",
        "\n",
        "# Verify we got the exact same period\n",
        "expected_start = \"2024-12-17\"\n",
        "expected_end = \"2025-02-07\"\n",
        "if str(test_start.date()) == expected_start and str(test_end.date()) == expected_end:\n",
        "    print(\"✅ Test period matches original exactly!\")\n",
        "else:\n",
        "    print(f\"⚠️  Test period mismatch! Expected: {expected_start} to {expected_end}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2ZA5JFLFjWa2",
        "outputId": "d08d2c14-25d6-4ee8-e494-d020ff96b43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Setting up feature extraction (exact same as original)...\n",
            "✅ Feature extraction functions ready\n",
            "📋 Expected feature names: ['raw_o', 'raw_h', 'raw_l', 'raw_c', 'raw_v', 'iso_0', 'iso_1', 'iso_2', 'iso_3', 'tf_1d', 'tf_4h', 'hl_range', 'price_change', 'upper_shadow', 'lower_shadow', 'volume_m']\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 5: FEATURE EXTRACTION FUNCTIONS (EXACT SAME AS ORIGINAL)\n",
        "# ========================================\n",
        "print(\"\\n🔧 Setting up feature extraction (exact same as original)...\")\n",
        "\n",
        "def parse_vector_column(vector_str):\n",
        "    \"\"\"Parse vector string to numpy array\"\"\"\n",
        "    if pd.isna(vector_str) or vector_str is None:\n",
        "        return None\n",
        "    if isinstance(vector_str, str):\n",
        "        s = vector_str.strip('[]\"')\n",
        "        try:\n",
        "            return np.array([float(x.strip()) for x in s.split(',')])\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return np.array(vector_str)\n",
        "\n",
        "def build_feature_vector(raw_ohlcv, iso_ohlc, tf, tf_list):\n",
        "    \"\"\"Build 16-feature vector\"\"\"\n",
        "    o, h, l, c, v = raw_ohlcv\n",
        "    features = list(raw_ohlcv)          # 5\n",
        "    features.extend(list(iso_ohlc))     # 4\n",
        "    features.extend([1 if tf == t else 0 for t in tf_list])  # 2\n",
        "    features.extend([\n",
        "        (h - l) / c if c else 0,        # hl_range\n",
        "        (c - o) / o if o else 0,        # price_change\n",
        "        (h - c) / c if c else 0,        # upper_shadow\n",
        "        (c - l) / c if c else 0,        # lower_shadow\n",
        "        v / 1_000_000,                  # volume_m\n",
        "    ])  # 5\n",
        "    return np.array(features, dtype=float)\n",
        "\n",
        "def extract_features_1d(row):\n",
        "    raw_ohlcv = parse_vector_column(row.get('raw_ohlcv_vec'))\n",
        "    iso_ohlc  = parse_vector_column(row.get('iso_ohlc'))\n",
        "    future    = row.get('future')\n",
        "    if raw_ohlcv is None or iso_ohlc is None or pd.isna(future):\n",
        "        return None, None\n",
        "    if len(raw_ohlcv) != 5 or len(iso_ohlc) != 4:\n",
        "        return None, None\n",
        "    return build_feature_vector(raw_ohlcv, iso_ohlc, '1d', TIMEFRAMES_ORDERED), int(future)\n",
        "\n",
        "print(f\"✅ Feature extraction functions ready\")\n",
        "print(f\"📋 Expected feature names: {FEATURE_NAMES}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pUt0WGH0jWa2",
        "outputId": "04c22c08-8c67-4d1f-90e1-585b2ac56e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Extracting test features (matching original process)...\n",
            "📊 Test samples from data: 35\n",
            "📊 Expected test samples: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting test features: 100%|██████████| 35/35 [00:00<00:00, 8139.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Extracted test features: (35, 16)\n",
            "📊 Test labels: 35\n",
            "✅ Test sample count matches original exactly!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 6: EXTRACT TEST FEATURES (EXACT SAME LOGIC)\n",
        "# ========================================\n",
        "print(\"\\n🔄 Extracting test features (matching original process)...\")\n",
        "\n",
        "df_1d = raw_data['1d']\n",
        "test_df = df_1d[(df_1d['timestamp'] >= test_start) & (df_1d['timestamp'] <= test_end)].copy()\n",
        "\n",
        "print(f\"📊 Test samples from data: {len(test_df)}\")\n",
        "print(f\"📊 Expected test samples: {original_results['test_samples']}\")\n",
        "\n",
        "# Extract test features and store detailed info\n",
        "X_test, y_test, test_timestamps = [], [], []\n",
        "test_rows_info = []\n",
        "\n",
        "for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Extracting test features\"):\n",
        "    fv, lbl = extract_features_1d(row)\n",
        "    if fv is not None:\n",
        "        X_test.append(fv)\n",
        "        y_test.append(lbl)\n",
        "        test_timestamps.append(row['timestamp'])\n",
        "        test_rows_info.append({\n",
        "            'timestamp': row['timestamp'],\n",
        "            'raw_ohlcv': parse_vector_column(row['raw_ohlcv_vec']),\n",
        "            'iso_ohlc':  parse_vector_column(row['iso_ohlc']),\n",
        "            'future': int(row['future']),\n",
        "            'feature_vector': fv\n",
        "        })\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(f\"📊 Extracted test features: {X_test.shape}\")\n",
        "print(f\"📊 Test labels: {len(y_test)}\")\n",
        "\n",
        "# Verify we got exactly the same number of samples\n",
        "if len(X_test) == original_results['test_samples']:\n",
        "    print(\"✅ Test sample count matches original exactly!\")\n",
        "else:\n",
        "    print(f\"⚠️  Sample count mismatch! Got {len(X_test)}, expected {original_results['test_samples']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z7wQ4RgrjWa3",
        "outputId": "de3f02fa-d8ab-4e86-9fd6-848713df814f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Making predictions with loaded model...\n",
            "\n",
            "🎯 REVERSE TEST RESULTS:\n",
            "✅ Test Accuracy: 0.7143\n",
            "✅ Test AUC: 0.7733\n",
            "📊 Threshold used: 0.57\n",
            "📊 Test predictions: [13 22]\n",
            "📊 Actual labels: [15 20]\n",
            "\n",
            "🔍 COMPARISON WITH ORIGINAL:\n",
            "Original Test Accuracy: 0.7143\n",
            "Original Test AUC: 0.7733\n",
            "Original Threshold: 0.57\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 7: MAKE PREDICTIONS WITH LOADED MODEL\n",
        "# ========================================\n",
        "print(\"\\n🧠 Making predictions with loaded model...\")\n",
        "\n",
        "# Scale test features with loaded scaler (same as original)\n",
        "X_test_scaled = scaler.transform(X_test) if len(X_test) else np.empty((0, len(FEATURE_NAMES)))\n",
        "\n",
        "# Make predictions\n",
        "test_pred_proba = gb_model.predict_proba(X_test_scaled)[:, 1] if len(X_test_scaled) else np.array([])\n",
        "test_pred = (test_pred_proba >= THRESHOLD).astype(int) if len(test_pred_proba) else np.array([])\n",
        "\n",
        "# Calculate metrics\n",
        "test_acc = accuracy_score(y_test, test_pred) if len(test_pred) else float('nan')\n",
        "test_auc = roc_auc_score(y_test, test_pred_proba) if (len(test_pred_proba) and len(np.unique(y_test))==2) else float('nan')\n",
        "\n",
        "print(f\"\\n🎯 REVERSE TEST RESULTS:\")\n",
        "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"✅ Test AUC: {test_auc:.4f}\")\n",
        "print(f\"📊 Threshold used: {THRESHOLD}\")\n",
        "if len(test_pred):\n",
        "    print(f\"📊 Test predictions: {np.bincount(test_pred)}\")\n",
        "    print(f\"📊 Actual labels: {np.bincount(y_test)}\")\n",
        "\n",
        "print(f\"\\n🔍 COMPARISON WITH ORIGINAL:\")\n",
        "print(f\"Original Test Accuracy: {original_results['test_accuracy']:.4f}\")\n",
        "print(f\"Original Test AUC: {original_results['test_auc']:.4f}\")\n",
        "print(f\"Original Threshold: {original_results['chosen_threshold']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j5yswRnYjWa3",
        "outputId": "a1c5a9b9-0064-49ff-b6fc-eb66d3dc50b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Detailed prediction-by-prediction comparison...\n",
            "📊 New predictions table: 35 rows\n",
            "📊 Original predictions table: 35 rows\n",
            "\n",
            "🔍 Comparing key prediction columns:\n",
            "  pred_prob_up: ✅ EXACT MATCH (max diff: 1.11e-16)\n",
            "  pred_label: ✅ EXACT MATCH\n",
            "  true_label: ✅ EXACT MATCH\n",
            "  correct: ✅ EXACT MATCH\n",
            "\n",
            "🎯 OVERALL COMPARISON: ✅ ALL PREDICTIONS MATCH EXACTLY!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 8: DETAILED PREDICTION-BY-PREDICTION COMPARISON\n",
        "# ========================================\n",
        "print(\"\\n🔍 Detailed prediction-by-prediction comparison...\")\n",
        "\n",
        "# Build new predictions table\n",
        "new_records = []\n",
        "for i, info in enumerate(test_rows_info):\n",
        "    ts   = info['timestamp']\n",
        "    fv   = info['feature_vector']\n",
        "    raw  = info['raw_ohlcv']\n",
        "    iso  = info['iso_ohlc']\n",
        "    true = info['future']\n",
        "\n",
        "    proba = float(test_pred_proba[i])\n",
        "    pred  = int(test_pred[i])\n",
        "    correct = bool(pred == true)\n",
        "    margin = proba - THRESHOLD\n",
        "\n",
        "    rec = {\n",
        "        'candle_index_in_test': i + 1,\n",
        "        'timestamp_utc': ts,\n",
        "        'date_utc': ts.date(),\n",
        "        'pred_prob_up': proba,\n",
        "        'pred_label': int(pred),\n",
        "        'true_label': int(true),\n",
        "        'correct': correct,\n",
        "        'threshold_used': THRESHOLD,\n",
        "        'decision_margin': margin,\n",
        "        'raw_o': raw[0], 'raw_h': raw[1], 'raw_l': raw[2], 'raw_c': raw[3], 'raw_v': raw[4],\n",
        "        'iso_0': iso[0], 'iso_1': iso[1], 'iso_2': iso[2], 'iso_3': iso[3],\n",
        "        'tf_1d': fv[FEATURE_NAMES.index('tf_1d')],\n",
        "        'tf_4h': fv[FEATURE_NAMES.index('tf_4h')],\n",
        "        'hl_range': fv[FEATURE_NAMES.index('hl_range')],\n",
        "        'price_change': fv[FEATURE_NAMES.index('price_change')],\n",
        "        'upper_shadow': fv[FEATURE_NAMES.index('upper_shadow')],\n",
        "        'lower_shadow': fv[FEATURE_NAMES.index('lower_shadow')],\n",
        "        'volume_m': fv[FEATURE_NAMES.index('volume_m')],\n",
        "    }\n",
        "    new_records.append(rec)\n",
        "\n",
        "new_pred_df = pd.DataFrame.from_records(new_records).sort_values(['date_utc','timestamp_utc']).reset_index(drop=True)\n",
        "\n",
        "print(f\"📊 New predictions table: {len(new_pred_df)} rows\")\n",
        "print(f\"📊 Original predictions table: {len(original_preds)} rows\")\n",
        "\n",
        "# Compare key columns\n",
        "comparison_cols = ['pred_prob_up', 'pred_label', 'true_label', 'correct']\n",
        "print(\"\\n🔍 Comparing key prediction columns:\")\n",
        "\n",
        "all_match = True\n",
        "for col in comparison_cols:\n",
        "    if col in original_preds.columns and col in new_pred_df.columns:\n",
        "        if col == 'pred_prob_up':\n",
        "            # For probabilities, allow small floating point differences\n",
        "            diff = np.abs(original_preds[col].values - new_pred_df[col].values)\n",
        "            max_diff = np.max(diff)\n",
        "            matches = np.allclose(original_preds[col].values, new_pred_df[col].values, rtol=1e-10, atol=1e-10)\n",
        "            print(f\"  {col}: {'✅ EXACT MATCH' if matches else '❌ MISMATCH'} (max diff: {max_diff:.2e})\")\n",
        "            if not matches:\n",
        "                all_match = False\n",
        "        else:\n",
        "            matches = (original_preds[col].values == new_pred_df[col].values).all()\n",
        "            print(f\"  {col}: {'✅ EXACT MATCH' if matches else '❌ MISMATCH'}\")\n",
        "            if not matches:\n",
        "                all_match = False\n",
        "    else:\n",
        "        print(f\"  {col}: ⚠️  Column not found in one of the datasets\")\n",
        "        all_match = False\n",
        "\n",
        "print(f\"\\n🎯 OVERALL COMPARISON: {'✅ ALL PREDICTIONS MATCH EXACTLY!' if all_match else '❌ SOME DIFFERENCES FOUND'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dd4TNQ8YjWa4",
        "outputId": "61478260-4365-4288-bfbd-9749b231a8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL VALIDATION SUMMARY\n",
            "================================================================================\n",
            "📊 Test Accuracy Match: ✅ (0.714286 vs 0.714286)\n",
            "📊 Test AUC Match: ✅ (0.773333 vs 0.773333)\n",
            "📊 Threshold Match: ✅ (0.57 vs 0.57)\n",
            "📊 Sample Count Match: ✅ (35 vs 35)\n",
            "📊 Prediction Details Match: ✅\n",
            "\n",
            "🎯 REVERSE TEST RESULT: 🎉 PERFECT MATCH! Model loaded and reproduced identical results.\n",
            "\n",
            "✅ The saved GB1D model has been successfully validated!\n",
            "✅ All predictions, metrics, and results match the original training run exactly.\n",
            "✅ The model can be confidently deployed for production use.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 9: FINAL VALIDATION SUMMARY\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL VALIDATION SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Metrics comparison\n",
        "acc_match = abs(test_acc - original_results['test_accuracy']) < 1e-10\n",
        "auc_match = abs(test_auc - original_results['test_auc']) < 1e-10\n",
        "threshold_match = abs(THRESHOLD - original_results['chosen_threshold']) < 1e-10\n",
        "\n",
        "print(f\"📊 Test Accuracy Match: {'✅' if acc_match else '❌'} ({test_acc:.6f} vs {original_results['test_accuracy']:.6f})\")\n",
        "print(f\"📊 Test AUC Match: {'✅' if auc_match else '❌'} ({test_auc:.6f} vs {original_results['test_auc']:.6f})\")\n",
        "print(f\"📊 Threshold Match: {'✅' if threshold_match else '❌'} ({THRESHOLD} vs {original_results['chosen_threshold']})\")\n",
        "print(f\"📊 Sample Count Match: {'✅' if len(X_test) == original_results['test_samples'] else '❌'} ({len(X_test)} vs {original_results['test_samples']})\")\n",
        "print(f\"📊 Prediction Details Match: {'✅' if all_match else '❌'}\")\n",
        "\n",
        "# Overall validation\n",
        "perfect_match = acc_match and auc_match and threshold_match and len(X_test) == original_results['test_samples'] and all_match\n",
        "\n",
        "print(f\"\\n🎯 REVERSE TEST RESULT: {'🎉 PERFECT MATCH! Model loaded and reproduced identical results.' if perfect_match else '⚠️  Some differences detected. Review above for details.'}\")\n",
        "\n",
        "if perfect_match:\n",
        "    print(\"\\n✅ The saved GB1D model has been successfully validated!\")\n",
        "    print(\"✅ All predictions, metrics, and results match the original training run exactly.\")\n",
        "    print(\"✅ The model can be confidently deployed for production use.\")\n",
        "else:\n",
        "    print(\"\\n⚠️  Validation failed. The loaded model does not reproduce identical results.\")\n",
        "    print(\"⚠️  This could indicate:\")\n",
        "    print(\"   - Data loading differences\")\n",
        "    print(\"   - Feature extraction differences\")\n",
        "    print(\"   - Model/scaler loading issues\")\n",
        "    print(\"   - Random seed or environment differences\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J69g2lmEjWa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4fc0ab21-92a3-40a1-a82d-3a92a76ae96f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving reverse test results...\n",
            "✅ Reverse test results saved to: /content/drive/MyDrive/daygent_v1_models/gb_1d_reverse_versionlock/gb1d_reverse_test_results.json\n",
            "✅ New predictions saved to: /content/drive/MyDrive/daygent_v1_models/gb_1d_reverse_versionlock/gb1d_reverse_test_predictions.csv\n",
            "\n",
            "🏁 Reverse test complete!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 10: SAVE REVERSE TEST RESULTS\n",
        "# ========================================\n",
        "print(\"\\n💾 Saving reverse test results...\")\n",
        "\n",
        "reverse_test_results = {\n",
        "    'reverse_test_date': datetime.now().isoformat(),\n",
        "    'perfect_match': perfect_match,\n",
        "    'loaded_model_results': {\n",
        "        'test_accuracy': float(test_acc),\n",
        "        'test_auc': float(test_auc),\n",
        "        'threshold_used': float(THRESHOLD),\n",
        "        'test_samples': int(len(X_test)),\n",
        "        'predictions_match': all_match\n",
        "    },\n",
        "    'original_results': original_results,\n",
        "    'differences': {\n",
        "        'accuracy_diff': float(abs(test_acc - original_results['test_accuracy'])),\n",
        "        'auc_diff': float(abs(test_auc - original_results['test_auc'])),\n",
        "        'sample_count_match': len(X_test) == original_results['test_samples']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save results to the reverse test directory\n",
        "results_path = os.path.join(REVERSE_MODEL_DIR, 'gb1d_reverse_test_results.json')\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(reverse_test_results, f, indent=2)\n",
        "\n",
        "# Save the new predictions for manual inspection if needed\n",
        "preds_path = os.path.join(REVERSE_MODEL_DIR, 'gb1d_reverse_test_predictions.csv')\n",
        "new_pred_df.to_csv(preds_path, index=False)\n",
        "\n",
        "print(f\"✅ Reverse test results saved to: {results_path}\")\n",
        "print(f\"✅ New predictions saved to: {preds_path}\")\n",
        "print(\"\\n🏁 Reverse test complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}