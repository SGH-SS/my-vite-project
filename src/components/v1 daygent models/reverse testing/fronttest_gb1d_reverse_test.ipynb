{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 1: CROSS-PLATFORM SETUP AND PATHS\n",
        "print(\"\ud83d\udd27 Setting up environment...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Try optional Colab drive mount for convenience\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    BASE_DIR = '/content/drive/MyDrive/daygent_v1_models'\n",
        "    print(\"\u2705 Google Drive mounted (Colab)\")\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "    BASE_DIR = './daygent_v1_models'\n",
        "    print(\"\u2705 Local environment detected\")\n",
        "\n",
        "# Core imports (install if missing)\n",
        "try:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "    import joblib\n",
        "except Exception as e:\n",
        "    print(f\"Installing missing packages due to: {e}\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'numpy', 'pandas', 'scikit-learn', 'tqdm', 'joblib', 'pyarrow'])\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "    import joblib\n",
        "\n",
        "# Locations\n",
        "FRONTTEST_DIR = os.path.join(BASE_DIR, 'spy_data_fronttest')\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'gb_1d')  # use the original gb_1d artifacts\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'gb_1d_reverse_fronttest')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"\ud83d\udd04 GB1D Reverse Test on Fronttest SPY 1D\")\n",
        "print(f\"\ud83d\udcc1 Fronttest dir: {FRONTTEST_DIR}\")\n",
        "print(f\"\ud83d\udcc1 Model dir:     {MODEL_DIR}\")\n",
        "print(f\"\ud83d\udcc1 Output dir:    {OUTPUT_DIR}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 2: LOAD MODEL CONFIG + ARTIFACTS\n",
        "print(\"\\n\ud83d\udce6 Loading model config and artifacts...\")\n",
        "\n",
        "config_path = os.path.join(MODEL_DIR, 'deployment_config.json')\n",
        "results_path = os.path.join(MODEL_DIR, 'results_gb_1d.json')\n",
        "model_path = os.path.join(MODEL_DIR, 'gb_1d_final.joblib')\n",
        "scaler_path = os.path.join(MODEL_DIR, 'scaler_1d.joblib')\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    CONFIG = json.load(f)\n",
        "\n",
        "with open(results_path, 'r') as f:\n",
        "    ORIGINAL_RESULTS = json.load(f)\n",
        "\n",
        "FEATURE_NAMES = CONFIG['feature_names']\n",
        "THRESHOLD = float(CONFIG.get('calibrated_threshold', 0.5))\n",
        "\n",
        "gb_model = joblib.load(model_path)\n",
        "scaler = joblib.load(scaler_path)\n",
        "\n",
        "print(f\"\u2705 Model loaded: {type(gb_model).__name__}\")\n",
        "print(f\"\u2705 Scaler loaded: {type(scaler).__name__}\")\n",
        "print(f\"\ud83d\udcca Feature contract: {len(FEATURE_NAMES)} features -> {FEATURE_NAMES}\")\n",
        "print(f\"\ud83c\udfaf Threshold: {THRESHOLD}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 3: LOAD FRONTTEST CSV (1d)\n",
        "print(\"\\n\ud83d\udce5 Loading fronttest CSVs...\")\n",
        "\n",
        "csv_1d = os.path.join(FRONTTEST_DIR, 'fronttest_spy_1d.csv')\n",
        "if not os.path.exists(csv_1d):\n",
        "    raise FileNotFoundError(f\"fronttest_spy_1d.csv not found in {FRONTTEST_DIR}\")\n",
        "\n",
        "df_1d = pd.read_csv(csv_1d)\n",
        "if 'timestamp' not in df_1d.columns:\n",
        "    raise ValueError(\"fronttest_spy_1d.csv must include 'timestamp'\")\n",
        "\n",
        "df_1d['timestamp'] = pd.to_datetime(df_1d['timestamp'])\n",
        "df_1d = df_1d.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "print(f\"\u2705 1d rows: {len(df_1d):,}; range: {df_1d['timestamp'].min()} \u2192 {df_1d['timestamp'].max()}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 4: FEATURE EXTRACTION HELPERS (MATCH gb_1d CONTRACT)\n",
        "print(\"\\n\ud83d\udd27 Preparing feature helpers (gb_1d 16-feature contract)...\")\n",
        "\n",
        "TIMEFRAMES = ['1d', '4h']  # one-hot order used originally\n",
        "\n",
        "def parse_vector_column(vector_str):\n",
        "    if pd.isna(vector_str) or vector_str is None:\n",
        "        return None\n",
        "    if isinstance(vector_str, str):\n",
        "        s = vector_str.strip('[]\"')\n",
        "        try:\n",
        "            return np.array([float(x.strip()) for x in s.split(',')])\n",
        "        except Exception:\n",
        "            return None\n",
        "    return np.array(vector_str)\n",
        "\n",
        "def build_feature_vector(raw_ohlcv, iso_ohlc, tf, tf_list):\n",
        "    o, h, l, c, v = raw_ohlcv\n",
        "    feats = list(raw_ohlcv)\n",
        "    feats.extend(list(iso_ohlc))\n",
        "    feats.extend([1 if tf == t else 0 for t in tf_list])\n",
        "    feats.extend([\n",
        "        (h - l) / c if c else 0.0,           # hl_range\n",
        "        (c - o) / o if o else 0.0,           # price_change\n",
        "        (h - c) / c if c else 0.0,           # upper_shadow\n",
        "        (c - l) / c if c else 0.0,           # lower_shadow\n",
        "        (v / 1_000_000.0) if v is not None else 0.0  # volume_m\n",
        "    ])\n",
        "    return np.array(feats, dtype=float)\n",
        "\n",
        "def row_to_features_and_label(row):\n",
        "    raw_ohlcv = parse_vector_column(row.get('raw_ohlcv_vec'))\n",
        "    iso_ohlc  = parse_vector_column(row.get('iso_ohlc'))\n",
        "    future    = row.get('future')\n",
        "    if raw_ohlcv is None or iso_ohlc is None or pd.isna(future):\n",
        "        return None, None\n",
        "    return build_feature_vector(raw_ohlcv, iso_ohlc, '1d', TIMEFRAMES), int(future)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 5: BUILD TEST MATRIX FROM FRONTTEST\n",
        "print(\"\\n\ud83d\udcd0 Building test matrices from fronttest data...\")\n",
        "\n",
        "X_test, y_test, meta = [], [], []\n",
        "for idx, row in tqdm(df_1d.iterrows(), total=len(df_1d), desc='Fronttest rows'):\n",
        "    feats, label = row_to_features_and_label(row)\n",
        "    if feats is None:\n",
        "        continue\n",
        "    X_test.append(feats)\n",
        "    y_test.append(label)\n",
        "    meta.append({\n",
        "        'index': int(idx),\n",
        "        'timestamp': row['timestamp'],\n",
        "        'close': row.get('close', np.nan),\n",
        "        'future': int(label)\n",
        "    })\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "print(f\"\u2705 Test matrix: {X_test.shape} (labels: {np.bincount(y_test) if len(y_test) else '[]'})\")\n",
        "\n",
        "if X_test.size == 0:\n",
        "    raise RuntimeError(\"No valid rows in fronttest CSV with required vectors + future label.\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 6: SCALE, PREDICT, METRICS\n",
        "print(\"\\n\ud83e\uddea Inference + metrics...\")\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "proba = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "pred = (proba >= THRESHOLD).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, pred)\n",
        "auc = roc_auc_score(y_test, proba) if len(np.unique(y_test)) == 2 else float('nan')\n",
        "print(f\"\ud83c\udfaf Accuracy: {acc:.4f}\")\n",
        "print(f\"\ud83c\udfaf AUC:      {auc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "print(\"\\n\ud83d\udcca Confusion Matrix:\\n\", cm)\n",
        "print(\"\\n\ud83d\udccb Classification Report:\\n\", classification_report(y_test, pred, digits=4))\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 7: DAY-BY-DAY ANALYSIS\n",
        "print(\"\\n\ud83d\udcc5 Day-by-day breakdown...\")\n",
        "\n",
        "results_rows = []\n",
        "for i, info in enumerate(meta):\n",
        "    ts = pd.Timestamp(info['timestamp'])\n",
        "    date_key = ts.date()\n",
        "    results_rows.append({\n",
        "        'date': str(date_key),\n",
        "        'timestamp': ts.isoformat(),\n",
        "        'close': float(info['close']) if info['close'] is not None and not pd.isna(info['close']) else None,\n",
        "        'future': int(info['future']),\n",
        "        'prob_up': float(proba[i]),\n",
        "        'pred': int(pred[i])\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results_rows)\n",
        "\n",
        "daily = df_results.groupby('date').apply(lambda g: pd.Series({\n",
        "    'n': len(g),\n",
        "    'acc': float((g['pred'] == g['future']).mean()),\n",
        "    'avg_prob_up': float(g['prob_up'].mean()),\n",
        "    'pred_up_rate': float((g['pred'] == 1).mean()),\n",
        "    'true_up_rate': float((g['future'] == 1).mean())\n",
        "})).reset_index()\n",
        "\n",
        "summary = {\n",
        "    'overall': {\n",
        "        'n_samples': int(len(df_results)),\n",
        "        'accuracy': float(acc),\n",
        "        'auc': float(auc),\n",
        "        'threshold': float(THRESHOLD)\n",
        "    },\n",
        "    'by_day': daily.to_dict(orient='records')\n",
        "}\n",
        "\n",
        "summary_path = os.path.join(OUTPUT_DIR, 'fronttest_summary_gb1d.json')\n",
        "preds_csv = os.path.join(OUTPUT_DIR, 'fronttest_predictions_gb1d.csv')\n",
        "daily_csv = os.path.join(OUTPUT_DIR, 'fronttest_daily_metrics_gb1d.csv')\n",
        "\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df_results.to_csv(preds_csv, index=False)\n",
        "daily.to_csv(daily_csv, index=False)\n",
        "\n",
        "print(f\"\\n\u2705 Saved: {summary_path}\")\n",
        "print(f\"\u2705 Saved: {preds_csv}\")\n",
        "print(f\"\u2705 Saved: {daily_csv}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %% [cell] STEP 8: DISPLAY TOP/BOTTOM DAYS\n",
        "print(\"\\n\ud83c\udfc1 Best/Worst days by accuracy (>=3 samples/day)...\")\n",
        "\n",
        "eligible = daily[daily['n'] >= 3].copy()\n",
        "if len(eligible):\n",
        "    print(\"Top 5 days:\")\n",
        "    print(eligible.sort_values('acc', ascending=False).head(5))\n",
        "    print(\"\\nBottom 5 days:\")\n",
        "    print(eligible.sort_values('acc', ascending=True).head(5))\n",
        "else:\n",
        "    print(\"Not enough samples per-day for breakdown; showing head:\")\n",
        "    print(daily.head())\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}