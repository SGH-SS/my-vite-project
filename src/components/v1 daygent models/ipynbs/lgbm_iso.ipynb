{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_OwhFktBMhc",
        "outputId": "ea458290-172c-4b30-9454-12c41f3d3189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Setting up dependencies...\n",
            "✅ Core dependencies already available\n",
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted (Colab environment)\n",
            "✅ Model directory: /content/drive/MyDrive/daygent_v1_models/lgbm_4h\n",
            "✅ Data directory: /content/drive/MyDrive/daygent_v1_models/spy_data_export\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 1: CROSS-PLATFORM DEPENDENCY MANAGEMENT\n",
        "# ========================================\n",
        "print(\"🔧 Setting up dependencies...\")\n",
        "\n",
        "# Cross-platform dependency installation\n",
        "try:\n",
        "    import pandas, numpy, sklearn, xgboost, matplotlib, seaborn, joblib, tqdm\n",
        "    import lightgbm as lgb\n",
        "    print(\"✅ Core dependencies already available\")\n",
        "except ImportError as e:\n",
        "    print(f\"Installing missing dependencies: {e}\")\n",
        "    import sys, subprocess\n",
        "    pkgs = ['pandas', 'numpy', 'scikit-learn', 'lightgbm',\n",
        "            'matplotlib', 'seaborn', 'joblib', 'tqdm', 'pyarrow']\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + pkgs)\n",
        "    import lightgbm as lgb\n",
        "    print(\"✅ Dependencies installed\")\n",
        "\n",
        "# Try to mount Google Drive if available (Colab environment)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    BASE_DIR = '/content/drive/MyDrive/daygent_v1_models'  # <— your new base folder\n",
        "    print(\"✅ Google Drive mounted (Colab environment)\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    BASE_DIR = './daygent_v1_models'\n",
        "    print(\"✅ Local environment detected\")\n",
        "\n",
        "# Core imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import collections\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'spy_data_export')\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'lgbm_4h')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Model directory: {MODEL_DIR}\")\n",
        "print(f\"✅ Data directory: {DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 2: LOAD ONLY 4H DATA\n",
        "# ========================================\n",
        "print(\"\\n📊 Loading ONLY 4H timeframe data...\")\n",
        "\n",
        "csv_file = os.path.join(DATA_DIR, 'spy_4h.csv')\n",
        "if not os.path.exists(csv_file):\n",
        "    raise FileNotFoundError(f\"❌ {csv_file} not found!\")\n",
        "\n",
        "df_4h = pd.read_csv(csv_file)\n",
        "df_4h['timestamp'] = pd.to_datetime(df_4h['timestamp'])\n",
        "df_4h = df_4h.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Loaded 4h data: {len(df_4h):,} candles\")\n",
        "print(f\"📅 Date range: {df_4h['timestamp'].min()} to {df_4h['timestamp'].max()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEKCVGB1BcCW",
        "outputId": "5812dae5-3ff1-4983-e0de-012972107475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Loading ONLY 4H timeframe data...\n",
            "✅ Loaded 4h data: 3,058 candles\n",
            "📅 Date range: 2019-01-07 14:30:00+00:00 to 2025-02-10 14:30:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 3: DEFINE TEST PERIOD (LAST 35 TRADING DAYS)\n",
        "# ========================================\n",
        "# Compute last 35 trading days common to 1d and 4h (matching your w2 style)\n",
        "csv_1d = os.path.join(DATA_DIR, 'spy_1d.csv')\n",
        "if not os.path.exists(csv_1d):\n",
        "    raise FileNotFoundError(f\"❌ {csv_1d} not found!\")\n",
        "\n",
        "df_1d = pd.read_csv(csv_1d)\n",
        "df_1d['timestamp'] = pd.to_datetime(df_1d['timestamp'])\n",
        "df_1d = df_1d.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "latest_start = max(df_1d['timestamp'].min(), df_4h['timestamp'].min())\n",
        "earliest_end = min(df_1d['timestamp'].max(), df_4h['timestamp'].max())\n",
        "\n",
        "one_d_dates = set(df_1d[(df_1d['timestamp'] >= latest_start) & (df_1d['timestamp'] <= earliest_end)]['timestamp'].dt.date.unique())\n",
        "four_h_dates = set(df_4h[(df_4h['timestamp'] >= latest_start) & (df_4h['timestamp'] <= earliest_end)]['timestamp'].dt.date.unique())\n",
        "common_dates = sorted(list(one_d_dates & four_h_dates))\n",
        "\n",
        "TEST_DAYS = 35\n",
        "if len(common_dates) == 0:\n",
        "    raise RuntimeError(\"❌ No common trading days between 1d and 4h in overlap window\")\n",
        "\n",
        "selected_days = common_dates[-min(TEST_DAYS, len(common_dates)) :]\n",
        "test_start = pd.Timestamp.combine(selected_days[0], pd.Timestamp.min.time()).tz_localize('UTC')\n",
        "test_end = pd.Timestamp.combine(selected_days[-1], pd.Timestamp.max.time()).tz_localize('UTC')\n",
        "\n",
        "print(f\"\\n📅 Total overlapping trading days: {len(common_dates)}\")\n",
        "print(f\"🎯 Test period: {test_start.date()} to {test_end.date()} ({len(selected_days)} days)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWZ6R2QNBg4i",
        "outputId": "6c23cb36-f519-41a2-e180-ad9c30845489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📅 Total overlapping trading days: 1532\n",
            "🎯 Test period: 2024-12-17 to 2025-02-07 (35 days)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 4: FEATURE EXTRACTION (MATCHING W2)\n",
        "# ========================================\n",
        "def parse_vector_column(vector_str):\n",
        "    \"\"\"Parse vector string to numpy array\"\"\"\n",
        "    if pd.isna(vector_str) or vector_str is None:\n",
        "        return None\n",
        "    if isinstance(vector_str, str):\n",
        "        vector_str = vector_str.strip('[]\"')\n",
        "        try:\n",
        "            return np.array([float(x.strip()) for x in vector_str.split(',')])\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return np.array(vector_str)\n",
        "\n",
        "TIMEFRAMES_ORDERED = ['1d', '4h']\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    'raw_o','raw_h','raw_l','raw_c','raw_v',\n",
        "    'iso_0','iso_1','iso_2','iso_3',\n",
        "    'tf_1d','tf_4h',\n",
        "    'hl_range','price_change','upper_shadow','lower_shadow','volume_m'\n",
        "]\n",
        "\n",
        "def build_feature_vector_4h(raw_ohlcv, iso_ohlc):\n",
        "    o, h, l, c, v = raw_ohlcv\n",
        "    features = []\n",
        "    features.extend(raw_ohlcv)  # 5\n",
        "    features.extend(iso_ohlc)   # 4\n",
        "    # TF one-hot (for ['1d','4h']) -> [0,1] since we're 4h\n",
        "    features.extend([0, 1])     # 2\n",
        "    # engineered\n",
        "    features.extend([\n",
        "        (h - l) / c if c != 0 else 0,   # hl_range\n",
        "        (c - o) / o if o != 0 else 0,   # price_change\n",
        "        (h - c) / c if c != 0 else 0,   # upper_shadow\n",
        "        (c - l) / c if c != 0 else 0,   # lower_shadow\n",
        "        v / 1_000_000,                  # volume_m\n",
        "    ]) # 5\n",
        "    return np.array(features, dtype=float)\n",
        "\n",
        "def extract_features_4h_only(row):\n",
        "    \"\"\"Extract features for 4h timeframe only - matching w2 exactly\"\"\"\n",
        "    raw_ohlcv = parse_vector_column(row.get('raw_ohlcv_vec'))\n",
        "    iso_ohlc = parse_vector_column(row.get('iso_ohlc'))\n",
        "    future = row.get('future')\n",
        "    if raw_ohlcv is None or iso_ohlc is None or pd.isna(future):\n",
        "        return None, None\n",
        "    if len(raw_ohlcv) != 5 or len(iso_ohlc) != 4:\n",
        "        return None, None\n",
        "    return build_feature_vector_4h(raw_ohlcv, iso_ohlc), int(future)\n"
      ],
      "metadata": {
        "id": "DV6xRRdgBnKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 5: EXTRACT TRAIN/TEST FEATURES\n",
        "# ========================================\n",
        "print(\"\\n🔄 Extracting features from 4h data...\")\n",
        "\n",
        "# Split data into train/test\n",
        "train_df = df_4h[df_4h['timestamp'] < test_start].copy()\n",
        "test_df  = df_4h[(df_4h['timestamp'] >= test_start) & (df_4h['timestamp'] <= test_end)].copy()\n",
        "\n",
        "print(f\"📊 Train samples: {len(train_df):,}\")\n",
        "print(f\"📊 Test samples: {len(test_df):,}\")\n",
        "\n",
        "# Extract training features\n",
        "X_train, y_train = [], []\n",
        "for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Extracting train features\"):\n",
        "    features, label = extract_features_4h_only(row)\n",
        "    if features is not None:\n",
        "        X_train.append(features)\n",
        "        y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(f\"\\n✅ Training features extracted: {X_train.shape}\")\n",
        "print(f\"📊 Class distribution: {np.bincount(y_train)}\")\n",
        "\n",
        "# Extract test features + keep raw fields for detailed reporting\n",
        "X_test, y_test, test_timestamps = [], [], []\n",
        "test_rows_info = []  # store raw info and feature vector\n",
        "\n",
        "for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Extracting test features\"):\n",
        "    fv, lbl = extract_features_4h_only(row)\n",
        "    if fv is not None:\n",
        "        X_test.append(fv)\n",
        "        y_test.append(lbl)\n",
        "        test_timestamps.append(row['timestamp'])\n",
        "        test_rows_info.append({\n",
        "            'timestamp': row['timestamp'],\n",
        "            'raw_ohlcv': parse_vector_column(row['raw_ohlcv_vec']),\n",
        "            'iso_ohlc': parse_vector_column(row['iso_ohlc']),\n",
        "            'future': int(row['future']),\n",
        "            'feature_vector': fv\n",
        "        })\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test  = np.array(y_test)\n",
        "\n",
        "print(f\"📊 Test features extracted: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilO5uzLgBq3f",
        "outputId": "e8837521-eb36-4e92-fb32-72285bf8cbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Extracting features from 4h data...\n",
            "📊 Train samples: 2,988\n",
            "📊 Test samples: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting train features: 100%|██████████| 2988/2988 [00:00<00:00, 15524.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Training features extracted: (2988, 16)\n",
            "📊 Class distribution: [1363 1625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting test features: 100%|██████████| 69/69 [00:00<00:00, 10138.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Test features extracted: (69, 16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 6: SCALE AND SPLIT (MATCHING W2)\n",
        "# ========================================\n",
        "scaler = StandardScaler()\n",
        "split_idx = int(len(X_train) * 0.8)\n",
        "print(f\"\\n🔧 Fitting scaler on first {split_idx:,} training samples...\")\n",
        "scaler.fit(X_train[:split_idx])\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_tr  = X_train_scaled[:split_idx]\n",
        "X_val = X_train_scaled[split_idx:]\n",
        "y_tr  = y_train[:split_idx]\n",
        "y_val = y_train[split_idx:]\n",
        "\n",
        "print(f\"📊 Training set: {X_tr.shape}\")\n",
        "print(f\"📊 Validation set: {X_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyT_j8FKBuB-",
        "outputId": "c17082d2-6aa2-4231-8204-2617838aff23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Fitting scaler on first 2,390 training samples...\n",
            "📊 Training set: (2390, 16)\n",
            "📊 Validation set: (598, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 7: TRAIN LIGHTGBM_FINANCIAL (EXACT PARAMS) + CALIBRATION + REFIT\n",
        "# ========================================\n",
        "print(\"\\n🚀 Training LightGBM_Financial with exact params...\")\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 60,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.1,\n",
        "    'n_estimators': 300,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'min_child_samples': 20,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'subsample_freq': 2,\n",
        "    'feature_fraction_bynode': 0.9,\n",
        "    'extra_trees': True,\n",
        "    'class_weight': 'balanced',\n",
        "    'random_state': 42,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Optional GPU acceleration if on Colab\n",
        "if IS_COLAB:\n",
        "    lgb_params['device_type'] = 'gpu'\n",
        "    lgb_params['gpu_device_id'] = 0\n",
        "    print(\"✅ GPU acceleration enabled\")\n",
        "\n",
        "# Fit on train slice only (no early stopping)\n",
        "model = lgb.LGBMClassifier(**lgb_params)\n",
        "print(\"🔄 Training LightGBM (no early stopping - full n_estimators)...\")\n",
        "model.fit(X_tr, y_tr)\n",
        "\n",
        "# Validate\n",
        "val_pred = model.predict(X_val)\n",
        "val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "val_acc = accuracy_score(y_val, val_pred)\n",
        "val_auc = roc_auc_score(y_val, val_pred_proba)\n",
        "print(f\"\\n✅ Validation Accuracy (t=0.50): {val_acc:.4f}\")\n",
        "print(f\"✅ Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "# Threshold calibration on validation\n",
        "thresholds = np.linspace(0.3, 0.7, 41)\n",
        "best_thr = 0.5\n",
        "best_val_acc = val_acc\n",
        "\n",
        "for thr in thresholds:\n",
        "    preds_thr = (val_pred_proba >= thr).astype(int)\n",
        "    acc_thr = accuracy_score(y_val, preds_thr)\n",
        "    if acc_thr > best_val_acc:\n",
        "        best_val_acc = acc_thr\n",
        "        best_thr = float(thr)\n",
        "\n",
        "print(f\"✅ Calibrated decision threshold on validation: {best_thr:.2f} (Acc={best_val_acc:.4f})\")\n",
        "\n",
        "# Refit on all in-sample (train + val)\n",
        "X_full = X_train_scaled\n",
        "y_full = y_train\n",
        "model_full = lgb.LGBMClassifier(**lgb_params)\n",
        "model_full.fit(X_full, y_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "G52L93r-BwC5",
        "outputId": "b5b788c8-c6a8-46b8-c5fb-18d10c18c4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training LightGBM_Financial with exact params...\n",
            "✅ GPU acceleration enabled\n",
            "🔄 Training LightGBM (no early stopping - full n_estimators)...\n",
            "\n",
            "✅ Validation Accuracy (t=0.50): 0.4749\n",
            "✅ Validation AUC: 0.5119\n",
            "✅ Calibrated decision threshold on validation: 0.30 (Acc=0.5502)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(class_weight='balanced', colsample_bytree=0.85,\n",
              "               device_type='gpu', extra_trees=True, feature_fraction_bynode=0.9,\n",
              "               gpu_device_id=0, max_depth=6, n_estimators=300, num_leaves=60,\n",
              "               objective='binary', random_state=42, reg_alpha=0.1,\n",
              "               reg_lambda=0.1, subsample=0.8, subsample_freq=2, verbose=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.85,\n",
              "               device_type=&#x27;gpu&#x27;, extra_trees=True, feature_fraction_bynode=0.9,\n",
              "               gpu_device_id=0, max_depth=6, n_estimators=300, num_leaves=60,\n",
              "               objective=&#x27;binary&#x27;, random_state=42, reg_alpha=0.1,\n",
              "               reg_lambda=0.1, subsample=0.8, subsample_freq=2, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.85,\n",
              "               device_type=&#x27;gpu&#x27;, extra_trees=True, feature_fraction_bynode=0.9,\n",
              "               gpu_device_id=0, max_depth=6, n_estimators=300, num_leaves=60,\n",
              "               objective=&#x27;binary&#x27;, random_state=42, reg_alpha=0.1,\n",
              "               reg_lambda=0.1, subsample=0.8, subsample_freq=2, verbose=-1)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 8: TEST + DETAILED DAY-BY-DAY / PRED-BY-PRED ANALYSIS\n",
        "# ========================================\n",
        "print(f\"\\n🧪 Testing on isolated {len(selected_days)}-day period...\")\n",
        "\n",
        "# Scale test data with the SAME scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Predict using refit model\n",
        "test_pred_proba = model_full.predict_proba(X_test_scaled)[:, 1]\n",
        "test_pred = (test_pred_proba >= best_thr).astype(int)\n",
        "\n",
        "# Metrics\n",
        "test_acc = accuracy_score(y_test, test_pred)\n",
        "test_auc = roc_auc_score(y_test, test_pred_proba)\n",
        "\n",
        "print(f\"\\n🎯 TEST RESULTS:\")\n",
        "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"✅ Test AUC: {test_auc:.4f}\")\n",
        "print(f\"📊 Test predictions: {np.bincount(test_pred)}\")\n",
        "print(f\"📊 Actual labels: {np.bincount(y_test)}\")\n",
        "\n",
        "# Build a detailed per-prediction table (DataFrame)\n",
        "records = []\n",
        "for i, info in enumerate(test_rows_info):\n",
        "    ts = info['timestamp']\n",
        "    fv = info['feature_vector']\n",
        "    raw = info['raw_ohlcv']\n",
        "    iso = info['iso_ohlc']\n",
        "    true = info['future']\n",
        "    proba = float(test_pred_proba[i])\n",
        "    pred  = int(test_pred[i])\n",
        "    correct = bool(pred == true)\n",
        "    margin = proba - best_thr\n",
        "\n",
        "    rec = {\n",
        "        'candle_index_in_test': i + 1,\n",
        "        'timestamp_utc': ts,\n",
        "        'date_utc': ts.date(),\n",
        "        'pred_prob_up': proba,\n",
        "        'pred_label': int(pred),     # 1 = up, 0 = down (per your 'future' field)\n",
        "        'true_label': int(true),\n",
        "        'correct': correct,\n",
        "        'threshold_used': best_thr,\n",
        "        'decision_margin': margin,\n",
        "        # Raw OHLCV & ISO for context\n",
        "        'raw_o': raw[0], 'raw_h': raw[1], 'raw_l': raw[2], 'raw_c': raw[3], 'raw_v': raw[4],\n",
        "        'iso_0': iso[0], 'iso_1': iso[1], 'iso_2': iso[2], 'iso_3': iso[3],\n",
        "        # Engineered features re-extracted from the feature vector (positions per FEATURE_NAMES)\n",
        "        'tf_1d': fv[FEATURE_NAMES.index('tf_1d')],\n",
        "        'tf_4h': fv[FEATURE_NAMES.index('tf_4h')],\n",
        "        'hl_range': fv[FEATURE_NAMES.index('hl_range')],\n",
        "        'price_change': fv[FEATURE_NAMES.index('price_change')],\n",
        "        'upper_shadow': fv[FEATURE_NAMES.index('upper_shadow')],\n",
        "        'lower_shadow': fv[FEATURE_NAMES.index('lower_shadow')],\n",
        "        'volume_m': fv[FEATURE_NAMES.index('volume_m')],\n",
        "    }\n",
        "    records.append(rec)\n",
        "\n",
        "pred_df = pd.DataFrame.from_records(records).sort_values(['date_utc','timestamp_utc']).reset_index(drop=True)\n",
        "\n",
        "# Save a machine-friendly CSV for your site\n",
        "pred_csv_path = os.path.join(MODEL_DIR, 'test_predictions.csv')\n",
        "pred_df.to_csv(pred_csv_path, index=False)\n",
        "\n",
        "# Build a human-readable TXT report grouped by day\n",
        "txt_lines = []\n",
        "txt_lines.append(\"=\"*90)\n",
        "txt_lines.append(\"LIGHTGBM 4H — DETAILED DAY-BY-DAY / PREDICTION-BY-PREDICTION REPORT\")\n",
        "txt_lines.append(\"=\"*90)\n",
        "txt_lines.append(f\"Test period: {test_start.date()} → {test_end.date()}\")\n",
        "txt_lines.append(f\"Total test candles: {len(pred_df)}\")\n",
        "txt_lines.append(f\"Calibrated threshold: {best_thr:.2f}\")\n",
        "txt_lines.append(f\"Overall Test Accuracy: {test_acc:.4f}\")\n",
        "txt_lines.append(f\"Overall Test AUC: {test_auc:.4f}\")\n",
        "txt_lines.append(\"\")\n",
        "\n",
        "for day in pred_df['date_utc'].unique():\n",
        "    day_block = pred_df[pred_df['date_utc'] == day]\n",
        "    correct_n = int(day_block['correct'].sum())\n",
        "    total_n   = len(day_block)\n",
        "    txt_lines.append(\"-\"*90)\n",
        "    txt_lines.append(f\"{day}  —  Day accuracy: {correct_n}/{total_n}  ({correct_n/total_n:.3f})\")\n",
        "    txt_lines.append(\"-\"*90)\n",
        "    for _, r in day_block.iterrows():\n",
        "        dir_word = \"UP\" if r['pred_label'] == 1 else \"DOWN\"\n",
        "        truth_word = \"UP\" if r['true_label'] == 1 else \"DOWN\"\n",
        "        right_wrong = \"✅ CORRECT\" if r['correct'] else \"❌ WRONG\"\n",
        "        txt_lines.append(\n",
        "            f\"[{int(r['candle_index_in_test']):02d}] {r['timestamp_utc']}  \"\n",
        "            f\"pred={dir_word}  p_up={r['pred_prob_up']:.4f}  thr={r['threshold_used']:.2f}  \"\n",
        "            f\"margin={r['decision_margin']:.4f}  truth={truth_word}  → {right_wrong}\"\n",
        "        )\n",
        "        # Include the contextual stats under each prediction\n",
        "        txt_lines.append(\n",
        "            f\"    OHLCV: O={r['raw_o']:.4f}, H={r['raw_h']:.4f}, L={r['raw_l']:.4f}, C={r['raw_c']:.4f}, V={r['raw_v']:.0f} | \"\n",
        "            f\"ISO: [{r['iso_0']:.4f}, {r['iso_1']:.4f}, {r['iso_2']:.4f}, {r['iso_3']:.4f}] | \"\n",
        "            f\"feats: hl={r['hl_range']:.4f}, dC={r['price_change']:.4f}, upSh={r['upper_shadow']:.4f}, \"\n",
        "            f\"loSh={r['lower_shadow']:.4f}, vol_m={r['volume_m']:.4f}\"\n",
        "        )\n",
        "    txt_lines.append(\"\")  # blank line between days\n",
        "\n",
        "report_path = os.path.join(MODEL_DIR, 'lgbm_4h_day_by_day.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"\\n\".join(txt_lines))\n",
        "\n",
        "print(f\"\\n📝 Saved detailed TXT report to: {report_path}\")\n",
        "print(f\"🧾 Saved machine-readable predictions to: {pred_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXt5037dB1y3",
        "outputId": "3b825bb9-77ca-44b5-a58a-47f879e36f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Testing on isolated 35-day period...\n",
            "\n",
            "🎯 TEST RESULTS:\n",
            "✅ Test Accuracy: 0.6377\n",
            "✅ Test AUC: 0.6474\n",
            "📊 Test predictions: [ 6 63]\n",
            "📊 Actual labels: [29 40]\n",
            "\n",
            "📝 Saved detailed TXT report to: /content/drive/MyDrive/daygent_v1_models/lgbm_4h/lgbm_4h_day_by_day.txt\n",
            "🧾 Saved machine-readable predictions to: /content/drive/MyDrive/daygent_v1_models/lgbm_4h/test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 9: SAVE MODEL AND RESULTS\n",
        "# ========================================\n",
        "print(\"\\n💾 Saving model and results...\")\n",
        "\n",
        "# Save model (the refit model) + scaler + threshold\n",
        "model_path  = os.path.join(MODEL_DIR, 'lightgbm_financial_4h_only.joblib')\n",
        "scaler_path = os.path.join(MODEL_DIR, 'scaler_4h_only.joblib')\n",
        "joblib.dump(model_full, model_path)\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "def _to_py(v):\n",
        "    try:\n",
        "        if isinstance(v, (np.integer, np.int64, np.int32)):\n",
        "            return int(v)\n",
        "        if isinstance(v, (np.floating,)):\n",
        "            return float(v)\n",
        "        return v\n",
        "    except Exception:\n",
        "        return v\n",
        "\n",
        "results = {\n",
        "    'test_accuracy': float(test_acc),\n",
        "    'test_auc': float(test_auc),\n",
        "    'validation_accuracy': float(best_val_acc),\n",
        "    'validation_auc': float(val_auc),\n",
        "    'train_samples': int(len(X_tr)),\n",
        "    'val_samples': int(len(X_val)),\n",
        "    'test_samples': int(len(X_test)),\n",
        "    'feature_count': int(X_train.shape[1]),\n",
        "    'chosen_threshold': float(best_thr),\n",
        "    'model_params': {k: _to_py(v) for k, v in lgb_params.items()},\n",
        "    'feature_names': FEATURE_NAMES,\n",
        "    'report_txt': os.path.basename(report_path),\n",
        "    'predictions_csv': os.path.basename(pred_csv_path),\n",
        "    'model_path': os.path.basename(model_path),\n",
        "    'scaler_path': os.path.basename(scaler_path),\n",
        "    'test_period': f\"{test_start.date()} to {test_end.date()}\"\n",
        "}\n",
        "\n",
        "import json\n",
        "with open(os.path.join(MODEL_DIR, 'results_4h_only.json'), 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"✅ Model saved to: {model_path}\")\n",
        "print(f\"✅ Scaler saved to: {scaler_path}\")\n",
        "print(\"✅ Results JSON saved as: results_4h_only.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jyEk-DzCAD6",
        "outputId": "bfb6381a-5c05-4b24-f998-29345e0bb5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving model and results...\n",
            "✅ Model saved to: /content/drive/MyDrive/daygent_v1_models/lgbm_4h/lightgbm_financial_4h_only.joblib\n",
            "✅ Scaler saved to: /content/drive/MyDrive/daygent_v1_models/lgbm_4h/scaler_4h_only.joblib\n",
            "✅ Results JSON saved as: results_4h_only.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 10: SAVE DEPLOYMENT ARTIFACTS (for your site)\n",
        "# ========================================\n",
        "import json\n",
        "from textwrap import dedent\n",
        "\n",
        "deployment_config = {\n",
        "    \"model_type\": \"LightGBMClassifier\",\n",
        "    \"timeframe\": \"4h\",\n",
        "    \"feature_contract_version\": \"v1\",\n",
        "    \"feature_names\": FEATURE_NAMES,\n",
        "    \"calibrated_threshold\": float(best_thr),\n",
        "    \"artifact_paths\": {\n",
        "        \"model_joblib\": \"lightgbm_financial_4h_only.joblib\",\n",
        "        \"scaler_joblib\": \"scaler_4h_only.joblib\"\n",
        "    },\n",
        "    \"inference_notes\": {\n",
        "        \"scaling\": \"StandardScaler fitted on first 80% of pre-test training data\",\n",
        "        \"one_hot\": {\"tf_1d\": 0, \"tf_4h\": 1},\n",
        "        \"expected_columns_in_csv\": [\"timestamp\", \"raw_ohlcv_vec\", \"iso_ohlc\", \"future\"]\n",
        "    },\n",
        "    \"lgbm_params\": {k: _to_py(v) for k, v in lgb_params.items()}\n",
        "}\n",
        "\n",
        "config_path = os.path.join(MODEL_DIR, \"deployment_config.json\")\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(deployment_config, f, indent=2)\n",
        "\n",
        "feature_schema = {\n",
        "    \"raw_ohlcv_vec\": {\n",
        "        \"desc\": \"Stringified list of [open, high, low, close, volume]\",\n",
        "        \"len\": 5,\n",
        "        \"dtype\": \"float\"\n",
        "    },\n",
        "    \"iso_ohlc\": {\n",
        "        \"desc\": \"Stringified list of 4 ISO-normalized OHLC values\",\n",
        "        \"len\": 4,\n",
        "        \"dtype\": \"float\"\n",
        "    },\n",
        "    \"engineered\": [\n",
        "        \"hl_range=(H-L)/C\",\n",
        "        \"price_change=(C-O)/O\",\n",
        "        \"upper_shadow=(H-C)/C\",\n",
        "        \"lower_shadow=(C-L)/C\",\n",
        "        \"volume_m=V/1e6\"\n",
        "    ],\n",
        "    \"tf_one_hot\": {\"tf_1d\": 0, \"tf_4h\": 1}\n",
        "}\n",
        "\n",
        "schema_path = os.path.join(MODEL_DIR, \"feature_schema.json\")\n",
        "with open(schema_path, \"w\") as f:\n",
        "    json.dump(feature_schema, f, indent=2)\n",
        "\n",
        "readme_text = dedent(f\"\"\"\n",
        "    ============================================\n",
        "    LightGBM 4H Inference — Deployment Notes\n",
        "    ============================================\n",
        "\n",
        "    Artifacts:\n",
        "    - Model:       {os.path.basename(model_path)}\n",
        "    - Scaler:      {os.path.basename(scaler_path)}\n",
        "    - Config:      {os.path.basename(config_path)}\n",
        "    - Feature schema: feature_schema.json\n",
        "    - Threshold:   {best_thr:.2f}\n",
        "    - Predictions: test_predictions.csv\n",
        "    - Report:      lgbm_4h_day_by_day.txt\n",
        "\n",
        "    Feature order (must match EXACTLY):\n",
        "    {FEATURE_NAMES}\n",
        "\n",
        "    Inference pipeline for your site:\n",
        "    1) Parse raw input row:\n",
        "       - Parse 'raw_ohlcv_vec' -> [o,h,l,c,v]\n",
        "       - Parse 'iso_ohlc'      -> [iso_0..iso_3]\n",
        "       - Add one-hot: tf_1d=0, tf_4h=1\n",
        "       - Compute engineered features as in feature_schema.json\n",
        "       - Concatenate into a single 16-length vector in the listed order.\n",
        "\n",
        "    2) Load scaler with joblib and call scaler.transform([vector]).\n",
        "    3) Load model with joblib and call model.predict_proba(scaled)[0,1].\n",
        "    4) If prob >= {best_thr:.2f} => predict UP (1); else DOWN (0).\n",
        "\n",
        "    Notes:\n",
        "    - This model was trained with class_weight='balanced'.\n",
        "    - Scaler was fit on the first 80% of pre-test (4h) training data.\n",
        "    - Keep feature order and scaling identical for consistent results.\n",
        "\"\"\").strip()\n",
        "\n",
        "readme_path = os.path.join(MODEL_DIR, \"README_DEPLOY.txt\")\n",
        "with open(readme_path, \"w\") as f:\n",
        "    f.write(readme_text)\n",
        "\n",
        "print(\"📦 Deployment artifacts saved:\")\n",
        "print(\" -\", config_path)\n",
        "print(\" -\", schema_path)\n",
        "print(\" -\", readme_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F30So39CFFE",
        "outputId": "c0ceabcf-b6d1-455a-c507-e362f1011a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Deployment artifacts saved:\n",
            " - /content/drive/MyDrive/daygent_v1_models/lgbm_4h/deployment_config.json\n",
            " - /content/drive/MyDrive/daygent_v1_models/lgbm_4h/feature_schema.json\n",
            " - /content/drive/MyDrive/daygent_v1_models/lgbm_4h/README_DEPLOY.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FINAL SUMMARY\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🏆 LIGHTGBM_FINANCIAL 4H-ONLY — COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\" • Model dir:    {MODEL_DIR}\")\n",
        "print(f\" • Test window:  {test_start.date()} → {test_end.date()}\")\n",
        "print(f\" • Test candles: {len(X_test)}\")\n",
        "print(f\" • Test Acc/AUC: {test_acc:.4f} / {test_auc:.4f}\")\n",
        "print(f\" • Threshold:    {best_thr:.2f}\")\n",
        "print(f\" • Saved files:  lightgbm_financial_4h_only.joblib, scaler_4h_only.joblib,\")\n",
        "print(f\"                 deployment_config.json, feature_schema.json, README_DEPLOY.txt,\")\n",
        "print(f\"                 test_predictions.csv, lgbm_4h_day_by_day.txt, results_4h_only.json\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "AI37cDjeCKg3",
        "outputId": "ad85e258-55cd-4964-9d5c-d3fdb7f44960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🏆 LIGHTGBM_FINANCIAL 4H-ONLY — COMPLETE\n",
            "======================================================================\n",
            " • Model dir:    /content/drive/MyDrive/daygent_v1_models/lgbm_4h\n",
            " • Test window:  2024-12-17 → 2025-02-07\n",
            " • Test candles: 69\n",
            " • Test Acc/AUC: 0.6377 / 0.6474\n",
            " • Threshold:    0.30\n",
            " • Saved files:  lightgbm_financial_4h_only.joblib, scaler_4h_only.joblib,\n",
            "                 deployment_config.json, feature_schema.json, README_DEPLOY.txt,\n",
            "                 test_predictions.csv, lgbm_4h_day_by_day.txt, results_4h_only.json\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}