{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JTGcb8E-cTDd",
        "outputId": "3dda1213-cb4d-492e-d97a-cfeb1abfc6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Setting up dependencies...\n",
            "Installing missing dependencies: No module named 'optuna'\n",
            "‚úÖ Dependencies installed\n",
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted ‚Üí remote persistence enabled\n",
            "üìÅ MODEL_DIR  : /content/drive/MyDrive/spy_prediction_models/blud\n",
            "üìÑ RESULTS TXT: /content/drive/MyDrive/spy_prediction_models/brothaman.txt\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 1: CROSS-PLATFORM DEPENDENCY MANAGEMENT\n",
        "# ========================================\n",
        "\n",
        "print(\"üîß Setting up dependencies...\")\n",
        "\n",
        "try:\n",
        "    import pandas, numpy, sklearn, xgboost, matplotlib, seaborn, joblib, tqdm\n",
        "    import lightgbm as lgb\n",
        "    import optuna\n",
        "    try:\n",
        "        from optuna.integration import LightGBMPruningCallback\n",
        "    except Exception:\n",
        "        LightGBMPruningCallback = None\n",
        "    try:\n",
        "        from optuna.importance import get_param_importances\n",
        "    except Exception:\n",
        "        get_param_importances = None\n",
        "    print(\"‚úÖ Core dependencies already available\")\n",
        "except ImportError as e:\n",
        "    print(f\"Installing missing dependencies: {e}\")\n",
        "    import sys, subprocess\n",
        "    pkgs = [\n",
        "        'pandas', 'numpy', 'scikit-learn', 'lightgbm', 'xgboost',\n",
        "        'matplotlib', 'seaborn', 'joblib', 'tqdm', 'pyarrow', 'optuna'\n",
        "    ]\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + pkgs)\n",
        "    import optuna\n",
        "    try:\n",
        "        from optuna.integration import LightGBMPruningCallback\n",
        "    except Exception:\n",
        "        LightGBMPruningCallback = None\n",
        "    try:\n",
        "        from optuna.importance import get_param_importances\n",
        "    except Exception:\n",
        "        get_param_importances = None\n",
        "    print(\"‚úÖ Dependencies installed\")\n",
        "\n",
        "# Google Drive (Colab) support ------------------------------------------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    IS_COLAB = True\n",
        "    BASE_DIR = '/content/drive/MyDrive/spy_prediction_models'\n",
        "    print(\"‚úÖ Google Drive mounted ‚Üí remote persistence enabled\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    BASE_DIR = './spy_prediction_models'\n",
        "    print(\"‚úÖ Local environment detected ‚Äì saving locally\")\n",
        "\n",
        "# Core imports ---------------------------------------------------------------\n",
        "import os, warnings, collections, json, itertools, random, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths ----------------------------------------------------------------------\n",
        "DATA_DIR  = os.path.join(BASE_DIR, 'spy_data_export')\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'blud')\n",
        "TXT_RESULTS_PATH = os.path.join(BASE_DIR, 'brothaman.txt')\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs('/tmp/training_chunks', exist_ok=True)\n",
        "print(f\"üìÅ MODEL_DIR  : {MODEL_DIR}\")\n",
        "print(f\"üìÑ RESULTS TXT: {TXT_RESULTS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VxR36qLOcTDh",
        "outputId": "c4a976ec-1ba4-47a8-fe23-1080077e2266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ†Ô∏è  Defining utility helpers ‚Ä¶\n",
            "‚úÖ Utility functions ready\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 2: UTILITY FUNCTIONS\n",
        "# ========================================\n",
        "print(\"üõ†Ô∏è  Defining utility helpers ‚Ä¶\")\n",
        "\n",
        "def left_asof(df, ts_col, target):\n",
        "    pos = df[ts_col].searchsorted(target, side='right') - 1\n",
        "    return None if pos < 0 else df.iloc[pos]\n",
        "\n",
        "def build_feature_vector(raw_ohlcv, iso_ohlc, tf, tf_list):\n",
        "    o, h, l, c, v = raw_ohlcv\n",
        "    features = list(raw_ohlcv)                # 5\n",
        "    features.extend(list(iso_ohlc))           # 4\n",
        "    features.extend([1 if tf == t else 0 for t in tf_list])  # TF one-hot (len=tf_list)\n",
        "    features.extend([\n",
        "        (h-l)/c if c else 0,\n",
        "        (c-o)/o if o else 0,\n",
        "        (h-c)/c if c else 0,\n",
        "        (c-l)/c if c else 0,\n",
        "        v/1_000_000,\n",
        "    ])\n",
        "    return np.array(features)\n",
        "\n",
        "def parse_vector_column(col):\n",
        "    if pd.isna(col) or col is None:\n",
        "        return None\n",
        "    if isinstance(col, str):\n",
        "        col = col.strip('[]\"')\n",
        "        try:\n",
        "            return np.array([float(x.strip()) for x in col.split(',')])\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return np.array(col)\n",
        "\n",
        "def timestamp_generator(raw_data, stop_ts, minutes=60):\n",
        "    min_ts = min(df['timestamp'].min() for df in raw_data.values())\n",
        "    cursor = min_ts\n",
        "    delta  = pd.Timedelta(minutes=minutes)\n",
        "    while cursor < stop_ts:\n",
        "        yield cursor, min(cursor+delta, stop_ts)\n",
        "        cursor += delta\n",
        "\n",
        "class SampleBalancer:\n",
        "    def __init__(self, max_ratio=3):\n",
        "        self.max_ratio = max_ratio\n",
        "        self.tf_seen   = collections.Counter()\n",
        "    def should_add(self, tf):\n",
        "        if tf == '4h':\n",
        "            return True\n",
        "        return True\n",
        "    def add(self, tf):\n",
        "        self.tf_seen[tf] += 1\n",
        "\n",
        "print(\"‚úÖ Utility functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RrlgFet4cTDh",
        "outputId": "e5e40343-51c4-41df-d01f-a4d08a287ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Loading 1D and 4H CSV files ‚Ä¶\n",
            "‚úÖ 1d: 2,547 candles (2014-12-23 14:30:00+00:00 ‚Üí 2025-02-07 14:30:00+00:00)\n",
            "‚úÖ 4h: 3,058 candles (2019-01-07 14:30:00+00:00 ‚Üí 2025-02-10 14:30:00+00:00)\n",
            "üéØ Test period: 2024-12-17 ‚Üí 2025-02-07  (35 trading days)\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 3: LOAD DATA FOR 1D & 4H\n",
        "# ========================================\n",
        "print(\"üìä Loading 1D and 4H CSV files ‚Ä¶\")\n",
        "TIMEFRAMES_ORDERED = ['1d', '4h']\n",
        "csv_files = {'1d': 'spy_1d.csv', '4h': 'spy_4h.csv'}\n",
        "\n",
        "raw_data, date_info = {}, {}\n",
        "for tf in TIMEFRAMES_ORDERED:\n",
        "    fp = os.path.join(DATA_DIR, csv_files[tf])\n",
        "    if not os.path.exists(fp):\n",
        "        print(f\"‚ùå {fp} missing ‚Äì abort\"); raise FileNotFoundError(fp)\n",
        "    df = pd.read_csv(fp)\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    raw_data[tf] = df\n",
        "    date_info[tf] = {\n",
        "        'start': df['timestamp'].min(),\n",
        "        'end'  : df['timestamp'].max(),\n",
        "        'count': len(df)\n",
        "    }\n",
        "    print(f\"‚úÖ {tf}: {len(df):,} candles ({date_info[tf]['start']} ‚Üí {date_info[tf]['end']})\")\n",
        "\n",
        "latest_start = max(d['start'] for d in date_info.values())\n",
        "earliest_end = min(d['end']   for d in date_info.values())\n",
        "\n",
        "common_dates=set(raw_data['1d'][ (raw_data['1d']['timestamp']>=latest_start) & (raw_data['1d']['timestamp']<=earliest_end) ]['timestamp'].dt.date.unique())\n",
        "common_dates &= set(raw_data['4h'][ (raw_data['4h']['timestamp']>=latest_start) & (raw_data['4h']['timestamp']<=earliest_end) ]['timestamp'].dt.date.unique())\n",
        "all_days = sorted(common_dates)\n",
        "\n",
        "TEST_DAYS = min(35, len(all_days))\n",
        "selected_days = all_days[-TEST_DAYS:]\n",
        "\n",
        "test_start = pd.Timestamp.combine(selected_days[0] , pd.Timestamp.min.time()).tz_localize('UTC')\n",
        "test_end   = pd.Timestamp.combine(selected_days[-1], pd.Timestamp.max.time()).tz_localize('UTC')\n",
        "\n",
        "print(f\"üéØ Test period: {test_start.date()} ‚Üí {test_end.date()}  ({TEST_DAYS} trading days)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cuDft_QrcTDi",
        "outputId": "22a44c0e-4a9e-45be-e600-fb6be9083fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Building optimizer ‚Ä¶\n",
            "‚úÖ Optimizer ready (seeded with params; accuracies will be computed on first run)\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 4: OPTIMIZER CLASS\n",
        "# ========================================\n",
        "print(\"ü§ñ Building optimizer ‚Ä¶\")\n",
        "from lightgbm import LGBMClassifier\n",
        "class Optimizer:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.balancer = SampleBalancer()\n",
        "        self.best = {}  # key = (model, tf)\n",
        "        self._init_results_file()\n",
        "        # Direction-aware tuning state -----------------------------------\n",
        "        # history[(model, tf)] = deque of dicts: {params, acc, changed_params}\n",
        "        self.history = collections.defaultdict(lambda: collections.deque(maxlen=300))\n",
        "        # param_stats[(model, tf)][param] = {weight, jitter}\n",
        "        self.param_stats = {}\n",
        "        # search_state[(model, tf)] = {last_params, last_acc, stagnation_count, exploration, max_changes}\n",
        "        self.search_state = {}\n",
        "        # Per-timeframe scalers, training splits, and eval cache ----------\n",
        "        self.scalers_tf = {}\n",
        "        self.train_data = {}\n",
        "        self.eval_cache = {}\n",
        "        # Bayes/Optuna studies per model-tf\n",
        "        self.studies = {}\n",
        "    # ------------------------------------------------------------------\n",
        "    def _init_results_file(self):\n",
        "        with open(TXT_RESULTS_PATH, 'a') as f:\n",
        "            f.write('\\n'+'='*90+'\\n')\n",
        "            f.write(f\"NEW SESSION {datetime.now():%Y-%m-%d %H:%M:%S}\\n\")\n",
        "            f.write('='*90+'\\n')\n",
        "    def log_best(self, model_name, tf, params, acc):\n",
        "        key=(model_name,tf)\n",
        "        # If no existing accuracy recorded, always set; otherwise set only if improved\n",
        "        current_acc = None\n",
        "        if key in self.best:\n",
        "            current_acc = self.best[key].get('acc', None)\n",
        "        if (current_acc is None) or (acc > current_acc):\n",
        "            self.best[key]={'params':params,'acc':acc,'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "            with open(TXT_RESULTS_PATH,'a') as f:\n",
        "                f.write(f\"üèÜ {model_name} {tf} {acc:.4f} {params}\\n\")\n",
        "            print(f\"üèÜ NEW BEST {model_name} {tf}: {acc:.4f}\")\n",
        "    # ------------------------------------------------------------------\n",
        "    def _init_param_stats_if_needed(self, model_name, tf, grid, default_jitter):\n",
        "        key=(model_name, tf)\n",
        "        if key not in self.param_stats:\n",
        "            self.param_stats[key] = {}\n",
        "        for p in grid.keys():\n",
        "            if p not in self.param_stats[key]:\n",
        "                self.param_stats[key][p] = {\n",
        "                    'weight': 1.0,\n",
        "                    'jitter': default_jitter\n",
        "                }\n",
        "        if key not in self.search_state:\n",
        "            self.search_state[key] = {\n",
        "                'last_params': None,\n",
        "                'last_acc': None,\n",
        "                'stagnation_count': 0,\n",
        "                'exploration': 0.2,   # will be reset per model below\n",
        "                'max_changes': 1      # will be reset per model below\n",
        "            }\n",
        "\n",
        "    def get_param_weights(self, model_name, tf, grid, default_jitter):\n",
        "        self._init_param_stats_if_needed(model_name, tf, grid, default_jitter)\n",
        "        key=(model_name, tf)\n",
        "        return {p: self.param_stats[key][p]['weight'] for p in grid.keys()}\n",
        "\n",
        "    def get_param_jitters(self, model_name, tf, grid, default_jitter):\n",
        "        self._init_param_stats_if_needed(model_name, tf, grid, default_jitter)\n",
        "        key=(model_name, tf)\n",
        "        return {p: self.param_stats[key][p]['jitter'] for p in grid.keys()}\n",
        "\n",
        "    def _nearly_equal(self, a, b, tol=1e-9):\n",
        "        try:\n",
        "            return abs(float(a) - float(b)) <= tol\n",
        "        except Exception:\n",
        "            return a == b\n",
        "\n",
        "    def _changed_params(self, prev_params, curr_params):\n",
        "        if prev_params is None:\n",
        "            return list(curr_params.keys())\n",
        "        changed=[]\n",
        "        for k,v in curr_params.items():\n",
        "            pv = prev_params.get(k, None)\n",
        "            if isinstance(v, float) or isinstance(pv, float):\n",
        "                if not self._nearly_equal(pv, v, tol=1e-8):\n",
        "                    changed.append(k)\n",
        "            else:\n",
        "                if pv != v:\n",
        "                    changed.append(k)\n",
        "        return changed\n",
        "\n",
        "    def record_result(self, model_name, tf, grid, params, acc, base_exploration, base_max_changes, default_jitter):\n",
        "        key=(model_name, tf)\n",
        "        self._init_param_stats_if_needed(model_name, tf, grid, default_jitter)\n",
        "        state = self.search_state[key]\n",
        "        last_acc = state['last_acc']\n",
        "        last_params = state['last_params']\n",
        "\n",
        "        changed = self._changed_params(last_params, params)\n",
        "        delta = None if last_acc is None else (acc - last_acc)\n",
        "\n",
        "        # Update param weights/jitters based on delta\n",
        "        if delta is not None and changed:\n",
        "            for p in changed:\n",
        "                ps = self.param_stats[key][p]\n",
        "                # Update weight with bounded additive rule\n",
        "                ps['weight'] += (0.5 * delta)\n",
        "                ps['weight'] = max(0.1, min(ps['weight'], 5.0))\n",
        "                # Update jitter slightly toward success direction\n",
        "                ps['jitter'] *= (1.0 + (0.5 * delta))\n",
        "                ps['jitter'] = max(0.02, min(ps['jitter'], 0.3))\n",
        "\n",
        "            # Stagnation detection and exploration scheduling\n",
        "            if delta <= 1e-5:\n",
        "                state['stagnation_count'] += 1\n",
        "            else:\n",
        "                state['stagnation_count'] = 0\n",
        "\n",
        "            if state['stagnation_count'] >= 5:\n",
        "                # Temporarily increase exploration and allow more changes\n",
        "                state['exploration'] = min(0.5, base_exploration + 0.15)\n",
        "                state['max_changes'] = min(base_max_changes + 1, max(1, len(grid)//2))\n",
        "            else:\n",
        "                # Anneal exploration back toward base\n",
        "                state['exploration'] = max(base_exploration, state['exploration'] * 0.9)\n",
        "                state['max_changes'] = max(base_max_changes, int(round(state['max_changes'] * 0.9)))\n",
        "\n",
        "        # Append to history\n",
        "        self.history[key].append({\n",
        "            'params': dict(params),\n",
        "            'acc': acc,\n",
        "            'changed_params': changed\n",
        "        })\n",
        "\n",
        "        # Update last state\n",
        "        state['last_params'] = dict(params)\n",
        "        state['last_acc'] = acc\n",
        "\n",
        "    def current_search_hyperparams(self, model_name, tf, base_exploration, base_max_changes, grid, default_jitter):\n",
        "        key=(model_name, tf)\n",
        "        self._init_param_stats_if_needed(model_name, tf, grid, default_jitter)\n",
        "        state = self.search_state[key]\n",
        "        # Initialize with base if first time\n",
        "        if state['last_acc'] is None:\n",
        "            state['exploration'] = base_exploration\n",
        "            state['max_changes'] = base_max_changes\n",
        "        return state['exploration'], state['max_changes']\n",
        "\n",
        "    # ------------------- dataset preparation ---------------------------\n",
        "    def prepare_datasets(self):\n",
        "        \"\"\"Build per-timeframe training/validation sets and evaluation caches.\"\"\"\n",
        "        self.scalers_tf = {}\n",
        "        self.train_data = {}\n",
        "        self.eval_cache = {}\n",
        "\n",
        "        for tf in TIMEFRAMES_ORDERED:\n",
        "            # Build training data for this timeframe only - use same approach as single script\n",
        "            df_tf = raw_data[tf]\n",
        "            train_df = df_tf[df_tf['timestamp'] < test_start].copy()\n",
        "\n",
        "            if len(train_df) == 0:\n",
        "                continue\n",
        "\n",
        "            # Extract features exactly like single script\n",
        "            X_list, y_list = [], []\n",
        "            for _, row in train_df.iterrows():\n",
        "                fv, lbl = self.extract(row, tf)\n",
        "                if fv is not None:\n",
        "                    X_list.append(fv)\n",
        "                    y_list.append(lbl)\n",
        "\n",
        "            if not X_list:\n",
        "                continue\n",
        "\n",
        "            X = np.array(X_list)\n",
        "            y = np.array(y_list)\n",
        "            split = int(len(X) * 0.8)\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(X[:split])\n",
        "            X_scaled = scaler.transform(X)\n",
        "            X_tr, X_val = X_scaled[:split], X_scaled[split:]\n",
        "            y_tr, y_val = y[:split], y[split:]\n",
        "            sample_weight_tr = compute_sample_weight('balanced', y_tr)\n",
        "\n",
        "            self.scalers_tf[tf] = scaler\n",
        "            self.train_data[tf] = {\n",
        "                'X_tr': X_tr, 'X_val': X_val, 'y_tr': y_tr, 'y_val': y_val,\n",
        "                'sample_weight_tr': sample_weight_tr\n",
        "            }\n",
        "\n",
        "            # Build evaluation cache for this timeframe\n",
        "            df_eval = raw_data[tf][(raw_data[tf]['timestamp'] >= test_start) & (raw_data[tf]['timestamp'] <= test_end)]\n",
        "            X_eval, y_eval = [], []\n",
        "            for _, row in df_eval.iterrows():\n",
        "                fv, lbl = self.extract(row, tf)\n",
        "                if fv is None:\n",
        "                    continue\n",
        "                xs = scaler.transform(fv.reshape(1, -1))[0]\n",
        "                X_eval.append(xs)\n",
        "                y_eval.append(lbl)\n",
        "            if X_eval:\n",
        "                self.eval_cache[tf] = {\n",
        "                    'X': np.array(X_eval),\n",
        "                    'y': np.array(y_eval)\n",
        "                }\n",
        "\n",
        "    # ------------------- time-series CV utils ----------------------------\n",
        "    def ts_cv_splits(self, X, n_splits=4, purge_frac=0.0):\n",
        "        \"\"\"Simple expanding-window splits with optional purge gap (as fraction of fold size).\"\"\"\n",
        "        n = len(X)\n",
        "        fold = n // (n_splits + 1)\n",
        "        for i in range(1, n_splits + 1):\n",
        "            train_end = fold * i\n",
        "            val_end = fold * (i + 1)\n",
        "            purge = int(fold * purge_frac)\n",
        "            train_idx_end = max(0, train_end - purge)\n",
        "            tr_idx = np.arange(0, train_idx_end)\n",
        "            va_idx = np.arange(train_end, val_end)\n",
        "            yield tr_idx, va_idx\n",
        "\n",
        "    # ------------------- Optuna search wrappers --------------------------\n",
        "    def get_study(self, name):\n",
        "        if name not in self.studies:\n",
        "            self.studies[name] = optuna.create_study(\n",
        "                direction='maximize',\n",
        "                sampler=optuna.samplers.TPESampler(multivariate=True, group=True, n_startup_trials=8),\n",
        "                pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=0)\n",
        "            )\n",
        "        return self.studies[name]\n",
        "\n",
        "    def optuna_objective_gb(self, tf, grid, base_params):\n",
        "        td = self.train_data.get(tf)\n",
        "        if td is None:\n",
        "            return lambda trial: 0.0\n",
        "        X = np.vstack([td['X_tr'], td['X_val']])\n",
        "        y = np.hstack([td['y_tr'], td['y_val']])\n",
        "\n",
        "        keys = list(grid.keys())\n",
        "        def suggest_from_grid(trial, k):\n",
        "            vals = grid[k]\n",
        "            if isinstance(vals[0], float):\n",
        "                lo, hi = min(vals), max(vals)\n",
        "                # use log sampling when range spans orders of magnitude (basic heuristic)\n",
        "                log = (hi/lo) > 20 if lo > 0 else False\n",
        "                return trial.suggest_float(k, lo, hi, log=log)\n",
        "            else:\n",
        "                return trial.suggest_categorical(k, vals)\n",
        "\n",
        "        def objective(trial):\n",
        "            # Start from base and perturb bounded by grid\n",
        "            params = dict(base_params) if base_params else {}\n",
        "            for k in keys:\n",
        "                params[k] = suggest_from_grid(trial, k)\n",
        "\n",
        "            accs = []\n",
        "            for tr_idx, va_idx in self.ts_cv_splits(X, n_splits=4, purge_frac=0.1):\n",
        "                X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "                X_va, y_va = X[va_idx], y[va_idx]\n",
        "                sw = compute_sample_weight('balanced', y_tr)\n",
        "                model = GradientBoostingClassifier(random_state=42, **params)\n",
        "                model.fit(X_tr, y_tr, sample_weight=sw)\n",
        "                pred = model.predict(X_va)\n",
        "                accs.append(accuracy_score(y_va, pred))\n",
        "            return float(np.mean(accs))\n",
        "        return objective\n",
        "\n",
        "    def optuna_objective_lgb(self, tf, grid, base_params):\n",
        "        td = self.train_data.get(tf)\n",
        "        if td is None:\n",
        "            return lambda trial: 0.0\n",
        "        X = np.vstack([td['X_tr'], td['X_val']])\n",
        "        y = np.hstack([td['y_tr'], td['y_val']])\n",
        "\n",
        "        keys = list(grid.keys())\n",
        "        def suggest_from_grid(trial, k):\n",
        "            vals = grid[k]\n",
        "            if isinstance(vals[0], float):\n",
        "                lo, hi = min(vals), max(vals)\n",
        "                log = (hi/lo) > 20 if lo > 0 else False\n",
        "                return trial.suggest_float(k, lo, hi, log=log)\n",
        "            else:\n",
        "                return trial.suggest_categorical(k, vals)\n",
        "\n",
        "        def objective(trial):\n",
        "            params = dict(base_params) if base_params else {}\n",
        "            for k in keys:\n",
        "                params[k] = suggest_from_grid(trial, k)\n",
        "\n",
        "            accs = []\n",
        "            for tr_idx, va_idx in self.ts_cv_splits(X, n_splits=4, purge_frac=0.1):\n",
        "                X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "                X_va, y_va = X[va_idx], y[va_idx]\n",
        "                model = lgb.LGBMClassifier(\n",
        "                    objective='binary', boosting_type='gbdt',\n",
        "                    class_weight='balanced', random_state=42, verbose=-1,\n",
        "                    device_type='gpu', gpu_device_id=0,\n",
        "                    **params\n",
        "                )\n",
        "                callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
        "                if LightGBMPruningCallback is not None:\n",
        "                    callbacks.append(LightGBMPruningCallback(trial, 'auc'))\n",
        "                model.fit(\n",
        "                    X_tr, y_tr,\n",
        "                    eval_set=[(X_va, y_va)],\n",
        "                    eval_metric='auc',\n",
        "                    callbacks=callbacks\n",
        "                )\n",
        "                pred = model.predict(X_va)\n",
        "                accs.append(accuracy_score(y_va, pred))\n",
        "            return float(np.mean(accs))\n",
        "        return objective\n",
        "    # ------------------------------------------------------------------\n",
        "    def feature_columns(self):\n",
        "        return (\n",
        "            ['raw_o','raw_h','raw_l','raw_c','raw_v']+\n",
        "            ['iso_0','iso_1','iso_2','iso_3']+\n",
        "            [f'tf_{t}' for t in TIMEFRAMES_ORDERED]+[\n",
        "            'hl_range','price_change','upper_shadow','lower_shadow','volume_m']\n",
        "        )\n",
        "\n",
        "    # ------------------- data collection -----------------------------\n",
        "    def collect_training(self):\n",
        "        X,y=[],[]\n",
        "        gen=timestamp_generator(raw_data,test_start,60)\n",
        "        for s,e in gen:\n",
        "            for tf in TIMEFRAMES_ORDERED:\n",
        "                df=raw_data[tf]\n",
        "                chunk=df[(df['timestamp']>=s)&(df['timestamp']<e)]\n",
        "                for _,row in chunk.iterrows():\n",
        "                    fv,lbl=self.extract(row,tf)\n",
        "                    if fv is not None:\n",
        "                        X.append(fv); y.append(lbl)\n",
        "        X=np.array(X); y=np.array(y)\n",
        "        split=int(len(X)*0.8)\n",
        "        self.scaler.fit(X[:split])\n",
        "        X=self.scaler.transform(X)\n",
        "        return X,y,split\n",
        "\n",
        "    def extract(self,row,tf):\n",
        "        raw = parse_vector_column(row.get('raw_ohlcv_vec'))\n",
        "        iso = parse_vector_column(row.get('iso_ohlc'))\n",
        "        fut = row.get('future')\n",
        "        if raw is None or iso is None or pd.isna(fut):\n",
        "            return None,None\n",
        "        if len(raw)!=5 or len(iso)!=4:\n",
        "            return None,None\n",
        "        return build_feature_vector(raw,iso,tf,TIMEFRAMES_ORDERED), int(fut)\n",
        "\n",
        "optimizer=Optimizer()\n",
        "\n",
        "# Pre-seed optimizer with parameter configurations ONLY (accuracy will be recomputed on first run)\n",
        "optimizer.best = {\n",
        "    ('GradientBoosting', '1d'): {\n",
        "        'params': {\n",
        "            'n_estimators': 150,\n",
        "            'max_depth': 5,\n",
        "            'learning_rate': 0.1625,\n",
        "            'subsample': 0.8043,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "        },\n",
        "        # 'acc' intentionally omitted to force baseline recomputation\n",
        "    },\n",
        "    ('GradientBoosting', '4h'): {\n",
        "        'params': {\n",
        "            'n_estimators': 75,\n",
        "            'max_depth': 9,\n",
        "            'learning_rate': 0.12,\n",
        "            'subsample': 0.85,\n",
        "            'min_samples_split': 12,\n",
        "            'min_samples_leaf': 1,\n",
        "        },\n",
        "    },\n",
        "    ('LightGBM_Financial', '4h'): {\n",
        "        'params': {\n",
        "            'num_leaves': 60,\n",
        "            'max_depth': 6,\n",
        "            'learning_rate': 0.1,\n",
        "            'n_estimators': 300,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 0.1,\n",
        "            'min_child_samples': 20,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.85,\n",
        "            'subsample_freq': 2,\n",
        "            'feature_fraction_bynode': 0.9,\n",
        "            'extra_trees': True,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "print(\"‚úÖ Optimizer ready (seeded with params; accuracies will be computed on first run)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xRwl7sWNcTDk",
        "outputId": "338e07ba-2832-41d9-e6ef-077aa8d11f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting adaptive optimization loop (Ctrl+C to stop) ‚Ä¶\n",
            "‚úÖ Base models saved in 'base models' folder\n",
            "\n",
            "üîÑ ITERATION 1\n",
            "üß™ Baseline verification pass ‚Äì testing seeded best configurations exactly‚Ä¶\n",
            "   ‚Üí GB 1d baseline (REFIT full): val_acc@best_thr=0.5328, thr=0.31, test_acc@best_thr=0.6857, test_acc@0.50=0.7429\n",
            "üèÜ NEW BEST GradientBoosting 1d: 0.6857\n",
            "üèÜ NEW BEST GradientBoosting 4h: 0.6957\n",
            "   ‚Üí LGB 4h baseline: val_acc@best_thr=0.5502, thr=0.30, test_acc@best_thr=0.6232, test_acc@0.50=0.5362\n",
            "üèÜ NEW BEST LightGBM_Financial 4h: 0.6232\n",
            "\n",
            "üîÑ ITERATION 2\n",
            "   ‚Üí GB 1d iter 2 (REFIT full): val_acc@best_thr=0.5328, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.5714, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 2 (REFIT full): val_acc@best_thr=0.5288, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 2: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 2: acc=0.4783, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 2: acc=0.5507, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.542306\tvalid_0's binary_logloss: 0.69205\n",
            "   ‚Üí LGB 4h iter 2: val_acc@best_thr=0.5686, thr=0.40, test_acc@best_thr=0.5797, test_acc@0.50=0.5362, explore=0.25, max_changes=2, changed=['num_leaves', 'learning_rate', 'n_estimators', 'reg_lambda', 'min_child_samples', 'colsample_bytree', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.480461\tvalid_0's binary_logloss: 0.693139\n",
            "   ‚Üí LGB 4h iter 2: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.25, max_changes=2, changed=['max_depth', 'min_child_samples']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.460951\tvalid_0's binary_logloss: 0.693594\n",
            "   ‚Üí LGB 4h iter 2: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.25, max_changes=2, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.6857\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('n_estimators', 1.0), ('max_depth', 1.0), ('learning_rate', 1.0)]\n",
            "   GradientBoosting 4h focus ‚Üí [('n_estimators', 1.0217391304347825), ('subsample', 1.0217391304347825), ('min_samples_split', 1.0217391304347825)]\n",
            "\n",
            "üîÑ ITERATION 3\n",
            "   ‚Üí GB 1d iter 3 (REFIT full): val_acc@best_thr=0.5487, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6286, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 3 (REFIT full): val_acc@best_thr=0.5129, thr=0.30, test_acc@best_thr=0.6571, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 3: acc=0.4638, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 3: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 3: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 3: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.25, max_changes=2, changed=['subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.513952\tvalid_0's binary_logloss: 0.693414\n",
            "   ‚Üí LGB 4h iter 3: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.25, max_changes=2, changed=['n_estimators', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473064\tvalid_0's binary_logloss: 0.693046\n",
            "   ‚Üí LGB 4h iter 3: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.25, max_changes=2, changed=['min_child_samples', 'colsample_bytree']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.6857\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.042857142857143), ('min_samples_leaf', 1.042857142857143), ('n_estimators', 1.0)]\n",
            "   GradientBoosting 4h focus ‚Üí [('min_samples_split', 1.0507246376811592), ('n_estimators', 1.0289855072463767), ('subsample', 1.007246376811594)]\n",
            "\n",
            "üîÑ ITERATION 4\n",
            "   ‚Üí GB 1d iter 4 (REFIT full): val_acc@best_thr=0.4950, thr=0.48, test_acc@best_thr=0.5429, test_acc@0.50=0.5429, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 4 (REFIT full): val_acc@best_thr=0.5109, thr=0.30, test_acc@best_thr=0.6857, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 4h iter 4: acc=0.5362, explore=0.20, max_changes=2, changed=['max_depth', 'subsample']\n",
            "   ‚Üí GB 4h iter 4: acc=0.5942, explore=0.20, max_changes=2, changed=['learning_rate', 'subsample']\n",
            "   ‚Üí GB 4h iter 4: acc=0.5507, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.508081\tvalid_0's binary_logloss: 0.695259\n",
            "   ‚Üí LGB 4h iter 4: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5652, explore=0.40, max_changes=3, changed=['max_depth', 'n_estimators', 'reg_alpha', 'reg_lambda', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692975\n",
            "   ‚Üí LGB 4h iter 4: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['max_depth']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.541446\tvalid_0's binary_logloss: 0.692573\n",
            "   ‚Üí LGB 4h iter 4: val_acc@best_thr=0.5686, thr=0.47, test_acc@best_thr=0.5797, test_acc@0.50=0.4638, explore=0.40, max_changes=3, changed=['num_leaves', 'learning_rate', 'n_estimators', 'reg_alpha', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'extra_trees']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.6857\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.1142857142857143), ('learning_rate', 1.0142857142857142), ('n_estimators', 1.0)]\n",
            "   GradientBoosting 4h focus ‚Üí [('min_samples_split', 1.0507246376811592), ('n_estimators', 1.0144927536231885), ('subsample', 0.9999999999999999)]\n",
            "\n",
            "üîÑ ITERATION 5\n",
            "   ‚Üí GB 1d iter 5 (REFIT full): val_acc@best_thr=0.5408, thr=0.33, test_acc@best_thr=0.6000, test_acc@0.50=0.6286, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 1d iter 5 (REFIT full): val_acc@best_thr=0.5427, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.7714, explore=0.15, max_changes=1, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 5: acc=0.4783, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 5: acc=0.5072, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 5: acc=0.4348, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.538137\tvalid_0's binary_logloss: 0.692864\n",
            "   ‚Üí LGB 4h iter 5: val_acc@best_thr=0.5702, thr=0.47, test_acc@best_thr=0.5797, test_acc@0.50=0.3623, explore=0.40, max_changes=3, changed=['max_depth', 'learning_rate', 'min_child_samples', 'subsample', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 5: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['min_child_samples']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.503992\tvalid_0's binary_logloss: 0.693725\n",
            "   ‚Üí LGB 4h iter 5: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4058, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.6857\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.0571428571428572), ('learning_rate', 1.0), ('n_estimators', 0.9857142857142858)]\n",
            "   GradientBoosting 4h focus ‚Üí [('min_samples_split', 1.0507246376811592), ('learning_rate', 0.9855072463768116), ('n_estimators', 0.9782608695652174)]\n",
            "\n",
            "üîÑ ITERATION 6\n",
            "   ‚Üí GB 1d iter 6 (REFIT full): val_acc@best_thr=0.4911, thr=0.57, test_acc@best_thr=0.7143, test_acc@0.50=0.7429, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "üèÜ NEW BEST GradientBoosting 1d: 0.7143\n",
            "   ‚Üí GB 1d iter 6 (REFIT full): val_acc@best_thr=0.5030, thr=0.33, test_acc@best_thr=0.6286, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 6: acc=0.6232, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate']\n",
            "   ‚Üí GB 4h iter 6: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate']\n",
            "   ‚Üí GB 4h iter 6: acc=0.4638, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473041\tvalid_0's binary_logloss: 0.693071\n",
            "   ‚Üí LGB 4h iter 6: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['max_depth', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.478987\tvalid_0's binary_logloss: 0.693591\n",
            "   ‚Üí LGB 4h iter 6: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473041\tvalid_0's binary_logloss: 0.693071\n",
            "   ‚Üí LGB 4h iter 6: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['n_estimators', 'colsample_bytree']\n",
            "\n",
            "üîÑ ITERATION 7\n",
            "   ‚Üí GB 1d iter 7 (REFIT full): val_acc@best_thr=0.5368, thr=0.32, test_acc@best_thr=0.6000, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 7 (REFIT full): val_acc@best_thr=0.5209, thr=0.31, test_acc@best_thr=0.6286, test_acc@0.50=0.5429, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 4h iter 7: acc=0.4638, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 7: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 7: acc=0.5072, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 7: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.523189\tvalid_0's binary_logloss: 0.692362\n",
            "   ‚Üí LGB 4h iter 7: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'reg_alpha', 'reg_lambda', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.480461\tvalid_0's binary_logloss: 0.693139\n",
            "   ‚Üí LGB 4h iter 7: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.40, max_changes=3, changed=['max_depth', 'reg_alpha', 'min_child_samples']\n",
            "\n",
            "üîÑ ITERATION 8\n",
            "   ‚Üí GB 1d iter 8 (REFIT full): val_acc@best_thr=0.5030, thr=0.31, test_acc@best_thr=0.5429, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 1d iter 8 (REFIT full): val_acc@best_thr=0.5308, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 4h iter 8: acc=0.4928, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 8: acc=0.5072, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 8: acc=0.5217, explore=0.20, max_changes=2, changed=['min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692969\n",
            "   ‚Üí LGB 4h iter 8: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['learning_rate', 'n_estimators', 'reg_lambda']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.546053\tvalid_0's binary_logloss: 0.692066\n",
            "   ‚Üí LGB 4h iter 8: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5507, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.481919\tvalid_0's binary_logloss: 0.693589\n",
            "   ‚Üí LGB 4h iter 8: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5362, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda']\n",
            "\n",
            "üîÑ ITERATION 9\n",
            "   ‚Üí GB 1d iter 9 (REFIT full): val_acc@best_thr=0.5308, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 1d iter 9 (REFIT full): val_acc@best_thr=0.5169, thr=0.38, test_acc@best_thr=0.7143, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 9: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth']\n",
            "   ‚Üí GB 4h iter 9: acc=0.5942, explore=0.20, max_changes=2, changed=['max_depth', 'learning_rate', 'subsample']\n",
            "   ‚Üí GB 4h iter 9: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.554789\tvalid_0's binary_logloss: 0.692417\n",
            "   ‚Üí LGB 4h iter 9: val_acc@best_thr=0.5686, thr=0.49, test_acc@best_thr=0.5507, test_acc@0.50=0.4638, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536833\tvalid_0's binary_logloss: 0.692626\n",
            "   ‚Üí LGB 4h iter 9: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['learning_rate', 'n_estimators', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.532579\tvalid_0's binary_logloss: 0.69313\n",
            "   ‚Üí LGB 4h iter 9: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.36, max_changes=3, changed=['min_child_samples', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 10\n",
            "   ‚Üí GB 1d iter 10 (REFIT full): val_acc@best_thr=0.5169, thr=0.38, test_acc@best_thr=0.7143, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 1d iter 10 (REFIT full): val_acc@best_thr=0.5308, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 4h iter 10: acc=0.5362, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 10: acc=0.4638, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 10: acc=0.4928, explore=0.20, max_changes=2, changed=['max_depth', 'learning_rate']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473075\tvalid_0's binary_logloss: 0.69343\n",
            "   ‚Üí LGB 4h iter 10: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4058, explore=0.32, max_changes=3, changed=['n_estimators', 'min_child_samples', 'subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.52164\tvalid_0's binary_logloss: 0.693302\n",
            "   ‚Üí LGB 4h iter 10: val_acc@best_thr=0.5736, thr=0.46, test_acc@best_thr=0.5797, test_acc@0.50=0.4783, explore=0.29, max_changes=3, changed=['num_leaves', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'colsample_bytree', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 10: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.26, max_changes=3, changed=['num_leaves']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.7143\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.0857142857142856), ('n_estimators', 1.0), ('min_samples_split', 1.0)]\n",
            "   GradientBoosting 4h focus ‚Üí [('n_estimators', 1.0869565217391306), ('subsample', 1.0507246376811594), ('min_samples_split', 1.0289855072463767)]\n",
            "\n",
            "üîÑ ITERATION 11\n",
            "   ‚Üí GB 1d iter 11 (REFIT full): val_acc@best_thr=0.5169, thr=0.38, test_acc@best_thr=0.7143, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 1d iter 11 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 11: acc=0.4783, explore=0.20, max_changes=2, changed=['learning_rate', 'subsample']\n",
            "   ‚Üí GB 4h iter 11: acc=0.5362, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 11: acc=0.4638, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'subsample', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 11: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.25, max_changes=3, changed=['num_leaves', 'n_estimators']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.497796\tvalid_0's binary_logloss: 0.693514\n",
            "   ‚Üí LGB 4h iter 11: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5217, explore=0.40, max_changes=3, changed=['max_depth', 'learning_rate', 'n_estimators', 'min_child_samples', 'subsample', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.512198\tvalid_0's binary_logloss: 0.693386\n",
            "   ‚Üí LGB 4h iter 11: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4638, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "\n",
            "üîÑ ITERATION 12\n",
            "   ‚Üí GB 1d iter 12 (REFIT full): val_acc@best_thr=0.5189, thr=0.35, test_acc@best_thr=0.6571, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 12 (REFIT full): val_acc@best_thr=0.5328, thr=0.31, test_acc@best_thr=0.6857, test_acc@0.50=0.7429, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "   ‚Üí GB 4h iter 12: acc=0.5507, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 12: acc=0.5797, explore=0.20, max_changes=2, changed=['learning_rate', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 12: acc=0.5217, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 12: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.548991\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 12: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4348, explore=0.40, max_changes=3, changed=['colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536811\tvalid_0's binary_logloss: 0.692645\n",
            "   ‚Üí LGB 4h iter 12: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['reg_alpha', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 13\n",
            "   ‚Üí GB 1d iter 13 (REFIT full): val_acc@best_thr=0.5308, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 1d iter 13 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 13: acc=0.5362, explore=0.20, max_changes=2, changed=['max_depth', 'learning_rate']\n",
            "   ‚Üí GB 4h iter 13: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 13: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 13: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['num_leaves', 'colsample_bytree', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473064\tvalid_0's binary_logloss: 0.693046\n",
            "   ‚Üí LGB 4h iter 13: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['n_estimators', 'min_child_samples', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.468486\tvalid_0's binary_logloss: 0.693755\n",
            "   ‚Üí LGB 4h iter 13: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5797, explore=0.40, max_changes=3, changed=['colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "\n",
            "üîÑ ITERATION 14\n",
            "   ‚Üí GB 1d iter 14 (REFIT full): val_acc@best_thr=0.5328, thr=0.31, test_acc@best_thr=0.6857, test_acc@0.50=0.7429, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "   ‚Üí GB 1d iter 14 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 14: acc=0.5507, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 14: acc=0.5217, explore=0.20, max_changes=2, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 14: acc=0.4638, explore=0.20, max_changes=2, changed=['subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 14: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['reg_lambda']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.509265\tvalid_0's binary_logloss: 0.693295\n",
            "   ‚Üí LGB 4h iter 14: val_acc@best_thr=0.5702, thr=0.47, test_acc@best_thr=0.5797, test_acc@0.50=0.4203, explore=0.40, max_changes=3, changed=['num_leaves', 'subsample', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.502329\tvalid_0's binary_logloss: 0.694135\n",
            "   ‚Üí LGB 4h iter 14: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4783, explore=0.40, max_changes=3, changed=['num_leaves', 'subsample']\n",
            "\n",
            "üîÑ ITERATION 15\n",
            "   ‚Üí GB 1d iter 15 (REFIT full): val_acc@best_thr=0.4811, thr=0.44, test_acc@best_thr=0.5714, test_acc@0.50=0.6286, explore=0.15, max_changes=1, changed=['max_depth', 'learning_rate', 'subsample']\n",
            "   ‚Üí GB 1d iter 15 (REFIT full): val_acc@best_thr=0.5010, thr=0.33, test_acc@best_thr=0.6000, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 4h iter 15: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 15: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 15: acc=0.4928, explore=0.20, max_changes=2, changed=['max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.548991\tvalid_0's binary_logloss: 0.692659\n",
            "   ‚Üí LGB 4h iter 15: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4348, explore=0.40, max_changes=3, changed=['learning_rate', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 15: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['n_estimators', 'min_child_samples']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.538115\tvalid_0's binary_logloss: 0.692551\n",
            "   ‚Üí LGB 4h iter 15: val_acc@best_thr=0.5769, thr=0.47, test_acc@best_thr=0.5652, test_acc@0.50=0.4928, explore=0.40, max_changes=3, changed=['subsample_freq', 'extra_trees']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.7143\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.157142857142857), ('learning_rate', 0.9999999999999998), ('n_estimators', 0.9714285714285713)]\n",
            "   GradientBoosting 4h focus ‚Üí [('n_estimators', 1.1014492753623188), ('min_samples_split', 1.072463768115942), ('subsample', 1.0144927536231882)]\n",
            "\n",
            "üîÑ ITERATION 16\n",
            "   ‚Üí GB 1d iter 16 (REFIT full): val_acc@best_thr=0.5706, thr=0.32, test_acc@best_thr=0.6000, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 16 (REFIT full): val_acc@best_thr=0.5467, thr=0.30, test_acc@best_thr=0.6286, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 4h iter 16: acc=0.6232, explore=0.20, max_changes=2, changed=['max_depth', 'learning_rate']\n",
            "   ‚Üí GB 4h iter 16: acc=0.5942, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 16: acc=0.5507, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.471413\tvalid_0's binary_logloss: 0.693742\n",
            "   ‚Üí LGB 4h iter 16: val_acc@best_thr=0.5702, thr=0.48, test_acc@best_thr=0.5797, test_acc@0.50=0.4203, explore=0.40, max_changes=3, changed=['subsample', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.532585\tvalid_0's binary_logloss: 0.693003\n",
            "   ‚Üí LGB 4h iter 16: val_acc@best_thr=0.5736, thr=0.45, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.36, max_changes=3, changed=['colsample_bytree', 'feature_fraction_bynode', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.485057\tvalid_0's binary_logloss: 0.693312\n",
            "   ‚Üí LGB 4h iter 16: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4348, explore=0.32, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'subsample_freq']\n",
            "\n",
            "üîÑ ITERATION 17\n",
            "   ‚Üí GB 1d iter 17 (REFIT full): val_acc@best_thr=0.5169, thr=0.38, test_acc@best_thr=0.7143, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 1d iter 17 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 17: acc=0.5507, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 17: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 17: acc=0.5942, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692975\n",
            "   ‚Üí LGB 4h iter 17: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.29, max_changes=3, changed=['max_depth']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.513303\tvalid_0's binary_logloss: 0.693992\n",
            "   ‚Üí LGB 4h iter 17: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5507, explore=0.26, max_changes=3, changed=['n_estimators', 'min_child_samples', 'subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.480461\tvalid_0's binary_logloss: 0.693141\n",
            "   ‚Üí LGB 4h iter 17: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.25, max_changes=3, changed=['learning_rate', 'n_estimators', 'min_child_samples']\n",
            "\n",
            "üîÑ ITERATION 18\n",
            "   ‚Üí GB 1d iter 18 (REFIT full): val_acc@best_thr=0.5268, thr=0.36, test_acc@best_thr=0.6571, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 18 (REFIT full): val_acc@best_thr=0.5209, thr=0.34, test_acc@best_thr=0.5714, test_acc@0.50=0.5429, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 4h iter 18: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 18: acc=0.4783, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 18: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.554077\tvalid_0's binary_logloss: 0.691604\n",
            "   ‚Üí LGB 4h iter 18: val_acc@best_thr=0.5702, thr=0.47, test_acc@best_thr=0.5507, test_acc@0.50=0.5507, explore=0.40, max_changes=3, changed=['learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.480461\tvalid_0's binary_logloss: 0.693145\n",
            "   ‚Üí LGB 4h iter 18: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.40, max_changes=3, changed=['reg_alpha', 'min_child_samples', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 18: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.36, max_changes=3, changed=['num_leaves', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 19\n",
            "   ‚Üí GB 1d iter 19 (REFIT full): val_acc@best_thr=0.5328, thr=0.31, test_acc@best_thr=0.6857, test_acc@0.50=0.7429, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "   ‚Üí GB 1d iter 19 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 19: acc=0.5797, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 19: acc=0.5797, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 19: acc=0.3768, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692642\n",
            "   ‚Üí LGB 4h iter 19: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.32, max_changes=3, changed=['learning_rate', 'colsample_bytree', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.49373\tvalid_0's binary_logloss: 0.693623\n",
            "   ‚Üí LGB 4h iter 19: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5362, explore=0.29, max_changes=3, changed=['learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.507039\tvalid_0's binary_logloss: 0.694332\n",
            "   ‚Üí LGB 4h iter 19: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.26, max_changes=3, changed=['reg_alpha', 'reg_lambda', 'subsample']\n",
            "\n",
            "üîÑ ITERATION 20\n",
            "   ‚Üí GB 1d iter 20 (REFIT full): val_acc@best_thr=0.5010, thr=0.32, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['n_estimators', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 1d iter 20 (REFIT full): val_acc@best_thr=0.5169, thr=0.31, test_acc@best_thr=0.6000, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 20: acc=0.5507, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 20: acc=0.4638, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 20: acc=0.5797, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.505142\tvalid_0's binary_logloss: 0.694662\n",
            "   ‚Üí LGB 4h iter 20: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4783, explore=0.25, max_changes=3, changed=['num_leaves', 'n_estimators', 'reg_lambda', 'min_child_samples', 'subsample', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.529863\tvalid_0's binary_logloss: 0.692102\n",
            "   ‚Üí LGB 4h iter 20: val_acc@best_thr=0.5753, thr=0.49, test_acc@best_thr=0.5217, test_acc@0.50=0.5652, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.525057\tvalid_0's binary_logloss: 0.693383\n",
            "   ‚Üí LGB 4h iter 20: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5072, explore=0.40, max_changes=3, changed=['max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'feature_fraction_bynode', 'extra_trees']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.7143\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.2285714285714284), ('learning_rate', 1.0285714285714282), ('n_estimators', 0.9857142857142855)]\n",
            "   GradientBoosting 4h focus ‚Üí [('min_samples_split', 1.282608695652174), ('n_estimators', 1.1666666666666665), ('learning_rate', 1.1521739130434783)]\n",
            "\n",
            "üîÑ ITERATION 21\n",
            "   ‚Üí GB 1d iter 21 (REFIT full): val_acc@best_thr=0.5189, thr=0.32, test_acc@best_thr=0.6286, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 21 (REFIT full): val_acc@best_thr=0.5169, thr=0.38, test_acc@best_thr=0.7143, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 21: acc=0.4058, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 21: acc=0.5362, explore=0.20, max_changes=2, changed=['max_depth']\n",
            "   ‚Üí GB 4h iter 21: acc=0.4783, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 21: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.36, max_changes=3, changed=['num_leaves', 'n_estimators', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692645\n",
            "   ‚Üí LGB 4h iter 21: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.32, max_changes=3, changed=['reg_alpha', 'reg_lambda', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.502255\tvalid_0's binary_logloss: 0.693431\n",
            "   ‚Üí LGB 4h iter 21: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4638, explore=0.29, max_changes=3, changed=['min_child_samples', 'colsample_bytree']\n",
            "\n",
            "üîÑ ITERATION 22\n",
            "   ‚Üí GB 1d iter 22 (REFIT full): val_acc@best_thr=0.5368, thr=0.30, test_acc@best_thr=0.6286, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 22 (REFIT full): val_acc@best_thr=0.5189, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['n_estimators', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 22: acc=0.4638, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 22: acc=0.5362, explore=0.20, max_changes=2, changed=['max_depth']\n",
            "   ‚Üí GB 4h iter 22: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536811\tvalid_0's binary_logloss: 0.692646\n",
            "   ‚Üí LGB 4h iter 22: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.26, max_changes=3, changed=['reg_alpha', 'reg_lambda', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473041\tvalid_0's binary_logloss: 0.693071\n",
            "   ‚Üí LGB 4h iter 22: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.25, max_changes=3, changed=['max_depth', 'colsample_bytree', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692645\n",
            "   ‚Üí LGB 4h iter 22: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['reg_lambda', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 23\n",
            "   ‚Üí GB 1d iter 23 (REFIT full): val_acc@best_thr=0.4970, thr=0.30, test_acc@best_thr=0.6571, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "   ‚Üí GB 1d iter 23 (REFIT full): val_acc@best_thr=0.5209, thr=0.33, test_acc@best_thr=0.6286, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 4h iter 23: acc=0.5217, explore=0.20, max_changes=2, changed=['min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 23: acc=0.5507, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth']\n",
            "   ‚Üí GB 4h iter 23: acc=0.5507, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.516759\tvalid_0's binary_logloss: 0.69383\n",
            "   ‚Üí LGB 4h iter 23: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4348, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536811\tvalid_0's binary_logloss: 0.692645\n",
            "   ‚Üí LGB 4h iter 23: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['reg_alpha', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.474579\tvalid_0's binary_logloss: 0.694215\n",
            "   ‚Üí LGB 4h iter 23: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'reg_lambda', 'min_child_samples']\n",
            "\n",
            "üîÑ ITERATION 24\n",
            "   ‚Üí GB 1d iter 24 (REFIT full): val_acc@best_thr=0.4930, thr=0.30, test_acc@best_thr=0.5429, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 24 (REFIT full): val_acc@best_thr=0.5328, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['max_depth', 'learning_rate', 'subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 24: acc=0.5217, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth']\n",
            "   ‚Üí GB 4h iter 24: acc=0.4783, explore=0.20, max_changes=2, changed=['max_depth', 'subsample']\n",
            "   ‚Üí GB 4h iter 24: acc=0.5072, explore=0.20, max_changes=2, changed=['subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692975\n",
            "   ‚Üí LGB 4h iter 24: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['max_depth', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692966\n",
            "   ‚Üí LGB 4h iter 24: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['num_leaves', 'reg_alpha', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 24: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['feature_fraction_bynode', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 25\n",
            "   ‚Üí GB 1d iter 25 (REFIT full): val_acc@best_thr=0.5149, thr=0.30, test_acc@best_thr=0.6286, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 25 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 25: acc=0.4638, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 25: acc=0.5072, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate']\n",
            "   ‚Üí GB 4h iter 25: acc=0.5217, explore=0.20, max_changes=2, changed=['learning_rate', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692975\n",
            "   ‚Üí LGB 4h iter 25: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['max_depth', 'n_estimators']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.480461\tvalid_0's binary_logloss: 0.693145\n",
            "   ‚Üí LGB 4h iter 25: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.40, max_changes=3, changed=['num_leaves', 'min_child_samples', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.538115\tvalid_0's binary_logloss: 0.692551\n",
            "   ‚Üí LGB 4h iter 25: val_acc@best_thr=0.5769, thr=0.47, test_acc@best_thr=0.5652, test_acc@0.50=0.4928, explore=0.40, max_changes=3, changed=['n_estimators', 'subsample_freq', 'extra_trees']\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.7143\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('subsample', 1.1857142857142855), ('learning_rate', 1.0857142857142854), ('max_depth', 1.0285714285714285)]\n",
            "   GradientBoosting 4h focus ‚Üí [('min_samples_split', 1.3768115942028987), ('learning_rate', 1.246376811594203), ('n_estimators', 1.1521739130434785)]\n",
            "\n",
            "üîÑ ITERATION 26\n",
            "   ‚Üí GB 1d iter 26 (REFIT full): val_acc@best_thr=0.5308, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 1d iter 26 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 4h iter 26: acc=0.4058, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 26: acc=0.5797, explore=0.20, max_changes=2, changed=['learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 26: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.49762\tvalid_0's binary_logloss: 0.69317\n",
            "   ‚Üí LGB 4h iter 26: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5362, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.52644\tvalid_0's binary_logloss: 0.692903\n",
            "   ‚Üí LGB 4h iter 26: val_acc@best_thr=0.5736, thr=0.46, test_acc@best_thr=0.5797, test_acc@0.50=0.5507, explore=0.36, max_changes=3, changed=['min_child_samples', 'subsample_freq', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.512853\tvalid_0's binary_logloss: 0.69393\n",
            "   ‚Üí LGB 4h iter 26: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4638, explore=0.32, max_changes=3, changed=['num_leaves', 'n_estimators', 'subsample']\n",
            "\n",
            "üîÑ ITERATION 27\n",
            "   ‚Üí GB 1d iter 27 (REFIT full): val_acc@best_thr=0.5268, thr=0.31, test_acc@best_thr=0.5714, test_acc@0.50=0.6857, explore=0.15, max_changes=1, changed=['min_samples_split']\n",
            "   ‚Üí GB 1d iter 27 (REFIT full): val_acc@best_thr=0.5427, thr=0.30, test_acc@best_thr=0.6571, test_acc@0.50=0.6571, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 4h iter 27: acc=0.4783, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 27: acc=0.4348, explore=0.20, max_changes=2, changed=['n_estimators', 'subsample']\n",
            "   ‚Üí GB 4h iter 27: acc=0.5072, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.525672\tvalid_0's binary_logloss: 0.692499\n",
            "   ‚Üí LGB 4h iter 27: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.29, max_changes=3, changed=['num_leaves', 'max_depth', 'n_estimators', 'reg_alpha', 'subsample', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 27: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.26, max_changes=3, changed=['num_leaves', 'reg_lambda', 'min_child_samples']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.485575\tvalid_0's binary_logloss: 0.693407\n",
            "   ‚Üí LGB 4h iter 27: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4928, explore=0.25, max_changes=3, changed=['num_leaves', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 28\n",
            "   ‚Üí GB 1d iter 28 (REFIT full): val_acc@best_thr=0.5427, thr=0.33, test_acc@best_thr=0.5429, test_acc@0.50=0.5714, explore=0.15, max_changes=1, changed=['subsample']\n",
            "   ‚Üí GB 1d iter 28 (REFIT full): val_acc@best_thr=0.5328, thr=0.31, test_acc@best_thr=0.6857, test_acc@0.50=0.7429, explore=0.15, max_changes=1, changed=['n_estimators']\n",
            "   ‚Üí GB 4h iter 28: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 28: acc=0.5652, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 28: acc=0.4928, explore=0.20, max_changes=2, changed=['n_estimators', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.536788\tvalid_0's binary_logloss: 0.692644\n",
            "   ‚Üí LGB 4h iter 28: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4493, explore=0.40, max_changes=3, changed=['n_estimators', 'extra_trees']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 28: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['num_leaves', 'n_estimators']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.55677\tvalid_0's binary_logloss: 0.690644\n",
            "   ‚Üí LGB 4h iter 28: val_acc@best_thr=0.5753, thr=0.41, test_acc@best_thr=0.5797, test_acc@0.50=0.5362, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 29\n",
            "   ‚Üí GB 1d iter 29 (REFIT full): val_acc@best_thr=0.5030, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split']\n",
            "   ‚Üí GB 1d iter 29 (REFIT full): val_acc@best_thr=0.5030, thr=0.31, test_acc@best_thr=0.5429, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['max_depth']\n",
            "   ‚Üí GB 4h iter 29: acc=0.5072, explore=0.20, max_changes=2, changed=['min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 29: acc=0.4638, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 29: acc=0.5072, explore=0.20, max_changes=2, changed=['max_depth', 'subsample']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692966\n",
            "   ‚Üí LGB 4h iter 29: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['reg_alpha', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.500057\tvalid_0's binary_logloss: 0.69321\n",
            "   ‚Üí LGB 4h iter 29: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5507, explore=0.40, max_changes=3, changed=['num_leaves', 'learning_rate', 'n_estimators', 'min_child_samples', 'subsample', 'colsample_bytree', 'subsample_freq', 'feature_fraction_bynode']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.541099\tvalid_0's binary_logloss: 0.692067\n",
            "   ‚Üí LGB 4h iter 29: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5072, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'subsample_freq', 'feature_fraction_bynode', 'extra_trees']\n",
            "\n",
            "üîÑ ITERATION 30\n",
            "   ‚Üí GB 1d iter 30 (REFIT full): val_acc@best_thr=0.5726, thr=0.30, test_acc@best_thr=0.5143, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 30 (REFIT full): val_acc@best_thr=0.5268, thr=0.30, test_acc@best_thr=0.6286, test_acc@0.50=0.7143, explore=0.15, max_changes=1, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 30: acc=0.5217, explore=0.20, max_changes=2, changed=['max_depth', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 30: acc=0.5507, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 30: acc=0.4203, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 30: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=[]\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692965\n",
            "   ‚Üí LGB 4h iter 30: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['n_estimators', 'min_child_samples']\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:24:11,113] A new study created in memory with name: no-name-800c4cee-dc9e-4253-aa92-60ef53478d13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.547186\tvalid_0's binary_logloss: 0.692798\n",
            "   ‚Üí LGB 4h iter 30: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.5217, explore=0.40, max_changes=3, changed=['num_leaves', 'learning_rate', 'min_child_samples', 'subsample', 'feature_fraction_bynode', 'extra_trees']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:24:14,989] Trial 0 finished with value: 0.48306772908366535 and parameters: {'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.14112577868437953, 'subsample': 0.7656912871376256, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.48306772908366535.\n",
            "[I 2025-08-18 23:24:21,768] Trial 1 finished with value: 0.4910358565737052 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.17293834278633796, 'subsample': 0.8682312478605234, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:24:26,205] Trial 2 finished with value: 0.48854581673306774 and parameters: {'n_estimators': 120, 'max_depth': 4, 'learning_rate': 0.1315349384693784, 'subsample': 0.8602018611505047, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:24:33,368] Trial 3 finished with value: 0.4750996015936255 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.08131692247585424, 'subsample': 0.838771401035266, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:24:40,798] Trial 4 finished with value: 0.4850597609561753 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.16521732826406266, 'subsample': 0.7656710125936952, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:24:45,871] Trial 5 finished with value: 0.46912350597609564 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1244886165079801, 'subsample': 0.7527649131720808, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:24:51,074] Trial 6 finished with value: 0.47808764940239046 and parameters: {'n_estimators': 180, 'max_depth': 3, 'learning_rate': 0.1146643460080855, 'subsample': 0.8742788787179423, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.4910358565737052.\n",
            "[I 2025-08-18 23:25:01,487] Trial 7 finished with value: 0.4950199203187251 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.17721391415496351, 'subsample': 0.8309688988460501, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:06,606] Trial 8 finished with value: 0.48904382470119523 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1619771457083436, 'subsample': 0.8152577298024859, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:16,429] Trial 9 finished with value: 0.4760956175298805 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.17077383930915568, 'subsample': 0.8758961594747943, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:26,074] Trial 10 finished with value: 0.4770916334661355 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.17073934318636097, 'subsample': 0.7626986655654062, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:32,739] Trial 11 finished with value: 0.4820717131474104 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.14080048949003116, 'subsample': 0.853102144577317, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:38,194] Trial 12 finished with value: 0.4915338645418327 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.17743041900101503, 'subsample': 0.8719775176391118, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:43,768] Trial 13 finished with value: 0.47808764940239046 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.16982718617148182, 'subsample': 0.8363260647312698, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:50,038] Trial 14 finished with value: 0.48306772908366535 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.16498833420701056, 'subsample': 0.8488481110811343, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:25:58,805] Trial 15 finished with value: 0.4865537848605578 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.16627132561083302, 'subsample': 0.8309547555207776, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:26:05,180] Trial 16 finished with value: 0.49252988047808766 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.1767995450908793, 'subsample': 0.8329793186580561, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:26:11,422] Trial 17 finished with value: 0.49352589641434264 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.17964593490226405, 'subsample': 0.8124234650153022, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:26:14,571] Trial 18 finished with value: 0.47460159362549803 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.17966807085216666, 'subsample': 0.7818440275049892, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.4950199203187251.\n",
            "[I 2025-08-18 23:26:20,785] Trial 19 finished with value: 0.5044820717131474 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.14491617667304335, 'subsample': 0.7804520382630175, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:26:26,074] Trial 20 finished with value: 0.48256972111553786 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.13818440065139445, 'subsample': 0.7962091964191047, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:26:31,111] Trial 21 finished with value: 0.4820717131474104 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.12898601547136732, 'subsample': 0.7624767352362227, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:26:41,432] Trial 22 finished with value: 0.4815737051792829 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.14461950163872206, 'subsample': 0.8351804857876843, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:26:47,510] Trial 23 finished with value: 0.4900398406374502 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.1657355737403734, 'subsample': 0.7590413469691834, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:26:55,964] Trial 24 finished with value: 0.4860557768924303 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1609499570468756, 'subsample': 0.787334480299845, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.5044820717131474.\n",
            "[I 2025-08-18 23:27:01,824] A new study created in memory with name: no-name-8b2645ce-fcfd-4209-8f62-d7503b33c104\n",
            "[I 2025-08-18 23:27:07,210] Trial 0 finished with value: 0.5054438860971525 and parameters: {'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.21001275203153996, 'subsample': 0.744861357026561, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:13,869] Trial 1 finished with value: 0.5037688442211056 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.16897265894795088, 'subsample': 0.7748939194546131, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:28,850] Trial 2 finished with value: 0.49413735343383586 and parameters: {'n_estimators': 150, 'max_depth': 10, 'learning_rate': 0.1449208752938103, 'subsample': 0.8429650325967342, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:34,870] Trial 3 finished with value: 0.4991624790619765 and parameters: {'n_estimators': 75, 'max_depth': 9, 'learning_rate': 0.21708108621934555, 'subsample': 0.7442787563831934, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:46,926] Trial 4 finished with value: 0.4991624790619765 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.16198344090412276, 'subsample': 0.7471480749179498, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:49,635] Trial 5 finished with value: 0.5008375209380235 and parameters: {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.20312163291166524, 'subsample': 0.726182122728302, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.5054438860971525.\n",
            "[I 2025-08-18 23:27:57,169] Trial 6 finished with value: 0.5087939698492463 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.21602435440519355, 'subsample': 0.7862637261091807, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5087939698492463.\n",
            "[I 2025-08-18 23:28:05,388] Trial 7 finished with value: 0.49874371859296485 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.20996261766662982, 'subsample': 0.8518912139274969, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5087939698492463.\n",
            "[I 2025-08-18 23:28:09,929] Trial 8 finished with value: 0.4903685092127303 and parameters: {'n_estimators': 75, 'max_depth': 6, 'learning_rate': 0.21317702076267572, 'subsample': 0.8229303569091264, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5087939698492463.\n",
            "[I 2025-08-18 23:28:14,066] Trial 9 finished with value: 0.49204355108877723 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.17218358049235474, 'subsample': 0.8697088547518252, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5087939698492463.\n",
            "[I 2025-08-18 23:28:20,966] Trial 10 finished with value: 0.5117252931323283 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.19259009718634887, 'subsample': 0.7153382043163146, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:24,556] Trial 11 finished with value: 0.49832495812395305 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.17692534169520852, 'subsample': 0.7432295089139213, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:30,293] Trial 12 finished with value: 0.49832495812395305 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.21737667478263606, 'subsample': 0.734924267137869, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:37,857] Trial 13 finished with value: 0.49539363484087096 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.20968231922094333, 'subsample': 0.7893856787272263, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:41,542] Trial 14 finished with value: 0.5100502512562815 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.18958421693796745, 'subsample': 0.7250314339767221, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:46,700] Trial 15 finished with value: 0.5016750418760468 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.18842488210849737, 'subsample': 0.7455010008545486, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:50,364] Trial 16 finished with value: 0.49623115577889443 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.19436400514486749, 'subsample': 0.713691417484202, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:28:57,107] Trial 17 finished with value: 0.49706867671691796 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.19323575248192632, 'subsample': 0.7084887747568985, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:01,192] Trial 18 finished with value: 0.48576214405360135 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.17848329918349246, 'subsample': 0.7879044809998029, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:05,854] Trial 19 finished with value: 0.4849246231155779 and parameters: {'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.21553027431615918, 'subsample': 0.7059947542944647, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:15,230] Trial 20 finished with value: 0.5050251256281407 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.16468509373421036, 'subsample': 0.7199995836777405, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:22,731] Trial 21 finished with value: 0.4995812395309883 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.2164612304569044, 'subsample': 0.7484443996923482, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:32,491] Trial 22 finished with value: 0.48743718592964824 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.19806665506792834, 'subsample': 0.7755370831080588, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:38,371] Trial 23 finished with value: 0.5071189279731994 and parameters: {'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.21135433919512697, 'subsample': 0.7221042752415309, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:41,083] Trial 24 finished with value: 0.5004187604690118 and parameters: {'n_estimators': 40, 'max_depth': 8, 'learning_rate': 0.21839471054258616, 'subsample': 0.702569560023403, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:29:58,247] Trial 25 finished with value: 0.4979061976549414 and parameters: {'n_estimators': 150, 'max_depth': 10, 'learning_rate': 0.21933012146666508, 'subsample': 0.8255477024277147, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:30:01,883] Trial 26 finished with value: 0.49958123953098826 and parameters: {'n_estimators': 40, 'max_depth': 10, 'learning_rate': 0.21951601737562737, 'subsample': 0.768657691590064, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:30:06,356] Trial 27 finished with value: 0.5033500837520939 and parameters: {'n_estimators': 75, 'max_depth': 7, 'learning_rate': 0.1936371126901038, 'subsample': 0.7047587423006285, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:30:10,091] Trial 28 finished with value: 0.5033500837520938 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.15752852288227565, 'subsample': 0.7335636274097257, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:30:18,175] Trial 29 finished with value: 0.4853433835845896 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.19541307139741299, 'subsample': 0.729300660967463, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5117252931323283.\n",
            "[I 2025-08-18 23:30:21,422] A new study created in memory with name: no-name-c297a856-351a-4b24-9321-4043df2645a4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.509133\tvalid_0's binary_logloss: 0.692614\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.523695\tvalid_0's binary_logloss: 0.693089\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.488359\tvalid_0's binary_logloss: 0.693642\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:22,330] Trial 0 finished with value: 0.49288107202680065 and parameters: {'num_leaves': 70, 'max_depth': 10, 'learning_rate': 0.08787987383472719, 'n_estimators': 200, 'reg_alpha': 0.05500927252675789, 'reg_lambda': 0.0865481793659917, 'min_child_samples': 20, 'subsample': 0.859810141092431, 'colsample_bytree': 0.8043904312642145, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7662476277918044, 'extra_trees': True}. Best is trial 0 with value: 0.49288107202680065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.472946\tvalid_0's binary_logloss: 0.693869\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.532568\tvalid_0's binary_logloss: 0.69244\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.475911\tvalid_0's binary_logloss: 0.693945\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.548096\tvalid_0's binary_logloss: 0.691412\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:23,653] Trial 1 finished with value: 0.4882747068676717 and parameters: {'num_leaves': 31, 'max_depth': 8, 'learning_rate': 0.07642031559123366, 'n_estimators': 300, 'reg_alpha': 0.02416836699544821, 'reg_lambda': 0.049816022085536565, 'min_child_samples': 20, 'subsample': 0.84085323676676, 'colsample_bytree': 0.8830392277513134, 'subsample_freq': 2, 'feature_fraction_bynode': 0.7316328096926676, 'extra_trees': True}. Best is trial 0 with value: 0.49288107202680065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.474062\tvalid_0's binary_logloss: 0.693918\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.531182\tvalid_0's binary_logloss: 0.692393\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.468625\tvalid_0's binary_logloss: 0.693346\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.509587\tvalid_0's binary_logloss: 0.693126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:24,513] Trial 2 finished with value: 0.4979061976549414 and parameters: {'num_leaves': 40, 'max_depth': 10, 'learning_rate': 0.04022869417694978, 'n_estimators': 400, 'reg_alpha': 0.030958905994726494, 'reg_lambda': 0.038545197977416935, 'min_child_samples': 30, 'subsample': 0.8749983693902456, 'colsample_bytree': 0.8420172531383056, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7462802192250104, 'extra_trees': True}. Best is trial 2 with value: 0.4979061976549414.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.481334\tvalid_0's binary_logloss: 0.693541\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.496831\tvalid_0's binary_logloss: 0.694557\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.527248\tvalid_0's binary_logloss: 0.691006\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.5212\tvalid_0's binary_logloss: 0.693365\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:26,085] Trial 3 finished with value: 0.4966499162479062 and parameters: {'num_leaves': 60, 'max_depth': 10, 'learning_rate': 0.0898995039537879, 'n_estimators': 300, 'reg_alpha': 0.061499694104693615, 'reg_lambda': 0.00637990870661298, 'min_child_samples': 10, 'subsample': 0.8998778488317151, 'colsample_bytree': 0.8501778856552263, 'subsample_freq': 2, 'feature_fraction_bynode': 0.8183065464393258, 'extra_trees': False}. Best is trial 2 with value: 0.4979061976549414.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.510729\tvalid_0's binary_logloss: 0.693184\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[37]\tvalid_0's auc: 0.528008\tvalid_0's binary_logloss: 0.690329\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.518143\tvalid_0's binary_logloss: 0.693013\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's auc: 0.533581\tvalid_0's binary_logloss: 0.691746\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:27,036] Trial 4 finished with value: 0.5033500837520939 and parameters: {'num_leaves': 50, 'max_depth': 8, 'learning_rate': 0.06915301459734725, 'n_estimators': 400, 'reg_alpha': 0.05085339991770395, 'reg_lambda': 0.08960377248404115, 'min_child_samples': 20, 'subsample': 0.8988703785247361, 'colsample_bytree': 0.8570496941582748, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7974088803128709, 'extra_trees': True}. Best is trial 4 with value: 0.5033500837520939.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.479755\tvalid_0's binary_logloss: 0.693999\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\tvalid_0's auc: 0.538383\tvalid_0's binary_logloss: 0.689575\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.482848\tvalid_0's binary_logloss: 0.693717\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[11]\tvalid_0's auc: 0.518157\tvalid_0's binary_logloss: 0.69267\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:27,924] Trial 5 finished with value: 0.5309882747068677 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.031219240342276012, 'n_estimators': 400, 'reg_alpha': 0.06610606611474791, 'reg_lambda': 0.034069414791970766, 'min_child_samples': 20, 'subsample': 0.8427646303166338, 'colsample_bytree': 0.846238223626753, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7114316534607749, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.526471\tvalid_0's binary_logloss: 0.692877\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[15]\tvalid_0's auc: 0.546026\tvalid_0's binary_logloss: 0.689299\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.483271\tvalid_0's binary_logloss: 0.69378\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's auc: 0.526509\tvalid_0's binary_logloss: 0.6924\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:29,003] Trial 6 finished with value: 0.5062814070351758 and parameters: {'num_leaves': 60, 'max_depth': 10, 'learning_rate': 0.03956298802267477, 'n_estimators': 200, 'reg_alpha': 0.03494567114900831, 'reg_lambda': 0.016826555755230257, 'min_child_samples': 20, 'subsample': 0.8952367138300603, 'colsample_bytree': 0.8198836782656741, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8929902055222158, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.503084\tvalid_0's binary_logloss: 0.693433\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.537054\tvalid_0's binary_logloss: 0.692499\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.470922\tvalid_0's binary_logloss: 0.693471\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[24]\tvalid_0's auc: 0.529916\tvalid_0's binary_logloss: 0.691786\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:30,352] Trial 7 finished with value: 0.48199329983249584 and parameters: {'num_leaves': 40, 'max_depth': 10, 'learning_rate': 0.046693378153172774, 'n_estimators': 300, 'reg_alpha': 0.0032389376229049363, 'reg_lambda': 0.040117624171044114, 'min_child_samples': 30, 'subsample': 0.8841921668643528, 'colsample_bytree': 0.830001963021936, 'subsample_freq': 2, 'feature_fraction_bynode': 0.709077331144497, 'extra_trees': True}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48237\tvalid_0's binary_logloss: 0.693489\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.542995\tvalid_0's binary_logloss: 0.6912\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.476761\tvalid_0's binary_logloss: 0.693569\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's auc: 0.515851\tvalid_0's binary_logloss: 0.692643\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:31,228] Trial 8 finished with value: 0.5180067001675042 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.04055509436745158, 'n_estimators': 400, 'reg_alpha': 0.08586158697721219, 'reg_lambda': 0.016988564917582986, 'min_child_samples': 20, 'subsample': 0.8113176312182179, 'colsample_bytree': 0.8316068777802513, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7275789722273335, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.527203\tvalid_0's binary_logloss: 0.692941\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.53369\tvalid_0's binary_logloss: 0.690983\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.482494\tvalid_0's binary_logloss: 0.693583\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[50]\tvalid_0's auc: 0.563638\tvalid_0's binary_logloss: 0.68799\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:32,158] Trial 9 finished with value: 0.5020938023450586 and parameters: {'num_leaves': 40, 'max_depth': 6, 'learning_rate': 0.04696247961492109, 'n_estimators': 150, 'reg_alpha': 0.09373510187876119, 'reg_lambda': 0.07438561765517267, 'min_child_samples': 20, 'subsample': 0.8558347302158373, 'colsample_bytree': 0.8298997384121773, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7286943580039691, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.519186\tvalid_0's binary_logloss: 0.692925\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.511008\tvalid_0's binary_logloss: 0.692168\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.512118\tvalid_0's binary_logloss: 0.692411\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.542085\tvalid_0's binary_logloss: 0.691553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:33,022] Trial 10 finished with value: 0.509212730318258 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.06328796675315475, 'n_estimators': 400, 'reg_alpha': 0.04424454343174263, 'reg_lambda': 0.013888784431023971, 'min_child_samples': 20, 'subsample': 0.8623488538807971, 'colsample_bytree': 0.8563769046683118, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7894607302434304, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.504721\tvalid_0's binary_logloss: 0.693401\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.502214\tvalid_0's binary_logloss: 0.693335\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.468597\tvalid_0's binary_logloss: 0.693549\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's auc: 0.510816\tvalid_0's binary_logloss: 0.692299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:33,999] Trial 11 finished with value: 0.48785594639866 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.031019195478800894, 'n_estimators': 400, 'reg_alpha': 0.055486963328635244, 'reg_lambda': 0.022029076062211, 'min_child_samples': 10, 'subsample': 0.8462667036027802, 'colsample_bytree': 0.8062013438993813, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7295959844280425, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.512434\tvalid_0's binary_logloss: 0.693087\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.54533\tvalid_0's binary_logloss: 0.691894\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.529326\tvalid_0's binary_logloss: 0.692471\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.487231\tvalid_0's binary_logloss: 0.693492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:34,897] Trial 12 finished with value: 0.4853433835845896 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.0519431260529759, 'n_estimators': 200, 'reg_alpha': 0.08803296344662753, 'reg_lambda': 0.01753376146508496, 'min_child_samples': 15, 'subsample': 0.8104048071367898, 'colsample_bytree': 0.8648557687204638, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7110232142806271, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.505201\tvalid_0's binary_logloss: 0.695152\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.501311\tvalid_0's binary_logloss: 0.69279\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.50509\tvalid_0's binary_logloss: 0.693012\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid_0's auc: 0.506174\tvalid_0's binary_logloss: 0.693246\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:35,698] Trial 13 finished with value: 0.48785594639866 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.04876494458861015, 'n_estimators': 400, 'reg_alpha': 0.07218153792037653, 'reg_lambda': 0.011143777177353882, 'min_child_samples': 30, 'subsample': 0.8203341269880846, 'colsample_bytree': 0.8345372430243541, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8010575112564584, 'extra_trees': True}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.478811\tvalid_0's binary_logloss: 0.693428\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\tvalid_0's auc: 0.516143\tvalid_0's binary_logloss: 0.692645\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.473022\tvalid_0's binary_logloss: 0.693793\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[22]\tvalid_0's auc: 0.541164\tvalid_0's binary_logloss: 0.690554\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:36,583] Trial 14 finished with value: 0.4958123953098828 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.03603448271329002, 'n_estimators': 400, 'reg_alpha': 0.08909354267414324, 'reg_lambda': 0.044554694896450274, 'min_child_samples': 20, 'subsample': 0.8172092180953764, 'colsample_bytree': 0.8514862874986054, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7832694905484314, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.509653\tvalid_0's binary_logloss: 0.693087\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[25]\tvalid_0's auc: 0.540194\tvalid_0's binary_logloss: 0.691031\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.474914\tvalid_0's binary_logloss: 0.693607\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[13]\tvalid_0's auc: 0.530029\tvalid_0's binary_logloss: 0.69171\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:37,601] Trial 15 finished with value: 0.5067001675041876 and parameters: {'num_leaves': 70, 'max_depth': 8, 'learning_rate': 0.030638444063243314, 'n_estimators': 400, 'reg_alpha': 0.0429218839421883, 'reg_lambda': 0.05930554065686727, 'min_child_samples': 20, 'subsample': 0.8736711157387036, 'colsample_bytree': 0.8531122636265961, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7711102273215523, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.493603\tvalid_0's binary_logloss: 0.693597\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\tvalid_0's auc: 0.54192\tvalid_0's binary_logloss: 0.689266\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.467645\tvalid_0's binary_logloss: 0.693942\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's auc: 0.517647\tvalid_0's binary_logloss: 0.692529\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:39,031] Trial 16 finished with value: 0.49288107202680065 and parameters: {'num_leaves': 31, 'max_depth': 10, 'learning_rate': 0.03322426218176225, 'n_estimators': 300, 'reg_alpha': 0.09932798044254834, 'reg_lambda': 0.004596203606467534, 'min_child_samples': 20, 'subsample': 0.8063579577936659, 'colsample_bytree': 0.846075900370727, 'subsample_freq': 2, 'feature_fraction_bynode': 0.7946388648048729, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.50139\tvalid_0's binary_logloss: 0.693704\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[11]\tvalid_0's auc: 0.520549\tvalid_0's binary_logloss: 0.691184\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.488372\tvalid_0's binary_logloss: 0.693752\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[37]\tvalid_0's auc: 0.546878\tvalid_0's binary_logloss: 0.689087\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:39,934] Trial 17 finished with value: 0.5041876046901173 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.05384025457107687, 'n_estimators': 400, 'reg_alpha': 0.06590494614139292, 'reg_lambda': 0.01610647775652615, 'min_child_samples': 20, 'subsample': 0.8067823298006164, 'colsample_bytree': 0.8097203486379777, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7202188501675123, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.544026\tvalid_0's binary_logloss: 0.693291\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[9]\tvalid_0's auc: 0.508989\tvalid_0's binary_logloss: 0.692542\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.492291\tvalid_0's binary_logloss: 0.693513\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[20]\tvalid_0's auc: 0.541529\tvalid_0's binary_logloss: 0.690761\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:40,827] Trial 18 finished with value: 0.5050251256281406 and parameters: {'num_leaves': 50, 'max_depth': 6, 'learning_rate': 0.034421617119116905, 'n_estimators': 300, 'reg_alpha': 0.03997381919559376, 'reg_lambda': 0.05913414605890031, 'min_child_samples': 20, 'subsample': 0.8475635570541451, 'colsample_bytree': 0.8363712462387841, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7198310338357672, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.518494\tvalid_0's binary_logloss: 0.693045\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[17]\tvalid_0's auc: 0.522654\tvalid_0's binary_logloss: 0.692215\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.450347\tvalid_0's binary_logloss: 0.69433\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[38]\tvalid_0's auc: 0.53384\tvalid_0's binary_logloss: 0.692422\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:42,274] Trial 19 finished with value: 0.4974874371859297 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.04064545405708929, 'n_estimators': 250, 'reg_alpha': 0.07288332672072659, 'reg_lambda': 0.050871951350315, 'min_child_samples': 10, 'subsample': 0.8327384046674857, 'colsample_bytree': 0.869091457435611, 'subsample_freq': 2, 'feature_fraction_bynode': 0.7379071546111137, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.506552\tvalid_0's binary_logloss: 0.692875\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's auc: 0.548746\tvalid_0's binary_logloss: 0.689295\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.529534\tvalid_0's binary_logloss: 0.692356\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.518932\tvalid_0's binary_logloss: 0.69281\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:43,518] Trial 20 finished with value: 0.5071189279731994 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.06088348537730802, 'n_estimators': 400, 'reg_alpha': 0.0970183320664931, 'reg_lambda': 0.0497214006743233, 'min_child_samples': 20, 'subsample': 0.8441465867188852, 'colsample_bytree': 0.8142051704116481, 'subsample_freq': 2, 'feature_fraction_bynode': 0.7021815562396795, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.529046\tvalid_0's binary_logloss: 0.692845\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's auc: 0.534984\tvalid_0's binary_logloss: 0.69082\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.511887\tvalid_0's binary_logloss: 0.692978\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[40]\tvalid_0's auc: 0.546053\tvalid_0's binary_logloss: 0.692585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:44,404] Trial 21 finished with value: 0.51214405360134 and parameters: {'num_leaves': 40, 'max_depth': 6, 'learning_rate': 0.0619826725978373, 'n_estimators': 400, 'reg_alpha': 0.04241762372189638, 'reg_lambda': 0.02713091529609943, 'min_child_samples': 30, 'subsample': 0.8480181161440115, 'colsample_bytree': 0.8671117180476416, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7903838861429379, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.501545\tvalid_0's binary_logloss: 0.693558\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's auc: 0.553692\tvalid_0's binary_logloss: 0.689611\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.514995\tvalid_0's binary_logloss: 0.692963\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.490615\tvalid_0's binary_logloss: 0.693768\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:45,238] Trial 22 finished with value: 0.5184254606365158 and parameters: {'num_leaves': 40, 'max_depth': 6, 'learning_rate': 0.05313051575024476, 'n_estimators': 150, 'reg_alpha': 0.019749663094366977, 'reg_lambda': 0.04968609596613849, 'min_child_samples': 30, 'subsample': 0.8324761675257799, 'colsample_bytree': 0.865849252217179, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8149855003517668, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.522814\tvalid_0's binary_logloss: 0.693052\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[16]\tvalid_0's auc: 0.530107\tvalid_0's binary_logloss: 0.690311\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.501746\tvalid_0's binary_logloss: 0.693212\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[28]\tvalid_0's auc: 0.526678\tvalid_0's binary_logloss: 0.693245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:46,101] Trial 23 finished with value: 0.5071189279731994 and parameters: {'num_leaves': 50, 'max_depth': 6, 'learning_rate': 0.03664909948739446, 'n_estimators': 150, 'reg_alpha': 0.014202891069442503, 'reg_lambda': 0.06815958280613245, 'min_child_samples': 30, 'subsample': 0.8475864506582509, 'colsample_bytree': 0.876636447819442, 'subsample_freq': 1, 'feature_fraction_bynode': 0.818141493078464, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.505184\tvalid_0's binary_logloss: 0.693299\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.55356\tvalid_0's binary_logloss: 0.688985\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.475731\tvalid_0's binary_logloss: 0.694003\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[20]\tvalid_0's auc: 0.532807\tvalid_0's binary_logloss: 0.692783\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:47,035] Trial 24 finished with value: 0.5121440536013401 and parameters: {'num_leaves': 40, 'max_depth': 8, 'learning_rate': 0.05565856082890649, 'n_estimators': 150, 'reg_alpha': 0.01345162663615877, 'reg_lambda': 0.04226623917549094, 'min_child_samples': 30, 'subsample': 0.8311817172709478, 'colsample_bytree': 0.8523089452082806, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7756767433663221, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.518465\tvalid_0's binary_logloss: 0.693886\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.528019\tvalid_0's binary_logloss: 0.691386\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.481024\tvalid_0's binary_logloss: 0.693727\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's auc: 0.526953\tvalid_0's binary_logloss: 0.692941\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:48,139] Trial 25 finished with value: 0.5171691792294808 and parameters: {'num_leaves': 70, 'max_depth': 10, 'learning_rate': 0.03253540016499753, 'n_estimators': 400, 'reg_alpha': 0.07309755856718786, 'reg_lambda': 0.07388142813420877, 'min_child_samples': 20, 'subsample': 0.8266912561824097, 'colsample_bytree': 0.8409240128827264, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7036283278157529, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.56149\tvalid_0's binary_logloss: 0.692217\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.505245\tvalid_0's binary_logloss: 0.692468\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.497596\tvalid_0's binary_logloss: 0.693462\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.510698\tvalid_0's binary_logloss: 0.693147\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:49,032] Trial 26 finished with value: 0.5020938023450586 and parameters: {'num_leaves': 40, 'max_depth': 6, 'learning_rate': 0.03590413279346513, 'n_estimators': 150, 'reg_alpha': 0.04262207380950385, 'reg_lambda': 0.042028838961512785, 'min_child_samples': 15, 'subsample': 0.829743453905228, 'colsample_bytree': 0.8832691884059064, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8180249490324628, 'extra_trees': True}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.501373\tvalid_0's binary_logloss: 0.693312\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.5036\tvalid_0's binary_logloss: 0.693109\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.486638\tvalid_0's binary_logloss: 0.693326\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.524242\tvalid_0's binary_logloss: 0.692676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:49,871] Trial 27 finished with value: 0.5041876046901173 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.03895708287894024, 'n_estimators': 400, 'reg_alpha': 0.08297904601370687, 'reg_lambda': 0.03705454554203391, 'min_child_samples': 20, 'subsample': 0.8487796619960403, 'colsample_bytree': 0.8395840970138536, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7370786715157444, 'extra_trees': True}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.497047\tvalid_0's binary_logloss: 0.693169\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.571066\tvalid_0's binary_logloss: 0.689834\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.466474\tvalid_0's binary_logloss: 0.693962\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[11]\tvalid_0's auc: 0.531611\tvalid_0's binary_logloss: 0.691537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:50,829] Trial 28 finished with value: 0.5087939698492462 and parameters: {'num_leaves': 31, 'max_depth': 8, 'learning_rate': 0.03811064238397015, 'n_estimators': 400, 'reg_alpha': 0.05777508712225899, 'reg_lambda': 0.02311686864200534, 'min_child_samples': 20, 'subsample': 0.8445446483860275, 'colsample_bytree': 0.8545402968449083, 'subsample_freq': 1, 'feature_fraction_bynode': 0.7072219523254054, 'extra_trees': False}. Best is trial 5 with value: 0.5309882747068677.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.524954\tvalid_0's binary_logloss: 0.69308\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.541046\tvalid_0's binary_logloss: 0.688542\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.524517\tvalid_0's binary_logloss: 0.69199\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[19]\tvalid_0's auc: 0.549937\tvalid_0's binary_logloss: 0.689689\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:51,661] Trial 29 finished with value: 0.5314070351758794 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.09156340532307691, 'n_estimators': 150, 'reg_alpha': 0.01935482713522382, 'reg_lambda': 0.07621033765236265, 'min_child_samples': 30, 'subsample': 0.8368215657952556, 'colsample_bytree': 0.8717360338196559, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8180984318738471, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.513682\tvalid_0's binary_logloss: 0.693281\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's auc: 0.558477\tvalid_0's binary_logloss: 0.686796\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.514995\tvalid_0's binary_logloss: 0.693035\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.490817\tvalid_0's binary_logloss: 0.69448\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:52,475] Trial 30 finished with value: 0.5184254606365158 and parameters: {'num_leaves': 50, 'max_depth': 6, 'learning_rate': 0.09127480945063715, 'n_estimators': 150, 'reg_alpha': 0.031215967908596542, 'reg_lambda': 0.09572579470527834, 'min_child_samples': 30, 'subsample': 0.8326910060792904, 'colsample_bytree': 0.8817309779394455, 'subsample_freq': 1, 'feature_fraction_bynode': 0.834373400548257, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.522814\tvalid_0's binary_logloss: 0.693043\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's auc: 0.531292\tvalid_0's binary_logloss: 0.6903\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.521876\tvalid_0's binary_logloss: 0.693058\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[16]\tvalid_0's auc: 0.537168\tvalid_0's binary_logloss: 0.693072\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:53,300] Trial 31 finished with value: 0.5217755443886096 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.09452687334890864, 'n_estimators': 150, 'reg_alpha': 0.02023689685320731, 'reg_lambda': 0.07838858810125399, 'min_child_samples': 30, 'subsample': 0.8483546518364633, 'colsample_bytree': 0.872490843060787, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8507136130028808, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.505184\tvalid_0's binary_logloss: 0.693631\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's auc: 0.503928\tvalid_0's binary_logloss: 0.693808\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.482522\tvalid_0's binary_logloss: 0.695365\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's auc: 0.561303\tvalid_0's binary_logloss: 0.686701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:54,150] Trial 32 finished with value: 0.5129815745393634 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.0968947063506886, 'n_estimators': 150, 'reg_alpha': 6.43125799854663e-05, 'reg_lambda': 0.08360396084827772, 'min_child_samples': 20, 'subsample': 0.8297792856985271, 'colsample_bytree': 0.869891681591795, 'subsample_freq': 1, 'feature_fraction_bynode': 0.8476208378075203, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.518294\tvalid_0's binary_logloss: 0.692983\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.52232\tvalid_0's binary_logloss: 0.690918\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.489881\tvalid_0's binary_logloss: 0.693785\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's auc: 0.517181\tvalid_0's binary_logloss: 0.692878\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:54,986] Trial 33 finished with value: 0.49497487437185933 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.08955195354758684, 'n_estimators': 150, 'reg_alpha': 0.020332620242151454, 'reg_lambda': 0.044929354811389856, 'min_child_samples': 30, 'subsample': 0.8498135413134204, 'colsample_bytree': 0.8523445866563245, 'subsample_freq': 1, 'feature_fraction_bynode': 0.734253349421656, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.501545\tvalid_0's binary_logloss: 0.69375\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.53775\tvalid_0's binary_logloss: 0.690717\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.541832\tvalid_0's binary_logloss: 0.691534\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[11]\tvalid_0's auc: 0.515312\tvalid_0's binary_logloss: 0.692539\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 23:30:56,248] Trial 34 finished with value: 0.501675041876047 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.07311868167236793, 'n_estimators': 150, 'reg_alpha': 0.03480066854094044, 'reg_lambda': 0.06604116209273553, 'min_child_samples': 30, 'subsample': 0.8437959932037414, 'colsample_bytree': 0.8806025316741275, 'subsample_freq': 2, 'feature_fraction_bynode': 0.8405768461167173, 'extra_trees': False}. Best is trial 29 with value: 0.5314070351758794.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.505493\tvalid_0's binary_logloss: 0.693402\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.51963\tvalid_0's binary_logloss: 0.693449\n",
            "üìà Current bests:\n",
            " ('GradientBoosting', '1d'): 0.7143\n",
            " ('GradientBoosting', '4h'): 0.6957\n",
            " ('LightGBM_Financial', '4h'): 0.6232\n",
            "   GradientBoosting 1d focus ‚Üí [('learning_rate', np.float64(2.0865728504018346)), ('max_depth', np.float64(1.8975992264059516)), ('n_estimators', np.float64(1.46703513798778))]\n",
            "   GradientBoosting 4h focus ‚Üí [('subsample', np.float64(2.556020717249001)), ('n_estimators', np.float64(1.503834735756718)), ('max_depth', np.float64(1.4418142284137467))]\n",
            "\n",
            "üîÑ ITERATION 31\n",
            "   ‚Üí GB 1d iter 31 (REFIT full): val_acc@best_thr=0.4891, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.4857, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 31 (REFIT full): val_acc@best_thr=0.5249, thr=0.30, test_acc@best_thr=0.5714, test_acc@0.50=0.5429, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 4h iter 31: acc=0.4928, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'min_samples_leaf']\n",
            "   ‚Üí GB 4h iter 31: acc=0.5072, explore=0.20, max_changes=2, changed=['max_depth', 'subsample']\n",
            "   ‚Üí GB 4h iter 31: acc=0.6957, explore=0.20, max_changes=2, changed=['n_estimators']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.502255\tvalid_0's binary_logloss: 0.693431\n",
            "   ‚Üí LGB 4h iter 31: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4638, explore=0.40, max_changes=3, changed=['min_child_samples', 'colsample_bytree', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.539726\tvalid_0's binary_logloss: 0.693071\n",
            "   ‚Üí LGB 4h iter 31: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4783, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'colsample_bytree', 'subsample_freq']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.479846\tvalid_0's binary_logloss: 0.69317\n",
            "   ‚Üí LGB 4h iter 31: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3768, explore=0.40, max_changes=3, changed=['min_child_samples', 'colsample_bytree']\n",
            "\n",
            "üîÑ ITERATION 32\n",
            "   ‚Üí GB 1d iter 32 (REFIT full): val_acc@best_thr=0.5229, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.5429, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 1d iter 32 (REFIT full): val_acc@best_thr=0.5010, thr=0.30, test_acc@best_thr=0.6000, test_acc@0.50=0.6000, explore=0.15, max_changes=1, changed=['learning_rate']\n",
            "   ‚Üí GB 4h iter 32: acc=0.5362, explore=0.20, max_changes=2, changed=['subsample', 'min_samples_split']\n",
            "   ‚Üí GB 4h iter 32: acc=0.6957, explore=0.20, max_changes=2, changed=['n_estimators']\n",
            "   ‚Üí GB 4h iter 32: acc=0.5072, explore=0.20, max_changes=2, changed=['n_estimators', 'max_depth', 'learning_rate', 'min_samples_split', 'min_samples_leaf']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.559874\tvalid_0's binary_logloss: 0.692781\n",
            "   ‚Üí LGB 4h iter 32: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4203, explore=0.40, max_changes=3, changed=['num_leaves', 'subsample', 'colsample_bytree']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.48311\tvalid_0's binary_logloss: 0.692988\n",
            "   ‚Üí LGB 4h iter 32: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.3913, explore=0.40, max_changes=3, changed=['max_depth', 'learning_rate', 'n_estimators']\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.496777\tvalid_0's binary_logloss: 0.693304\n",
            "   ‚Üí LGB 4h iter 32: val_acc@best_thr=0.5669, thr=0.30, test_acc@best_thr=0.5797, test_acc@0.50=0.4783, explore=0.40, max_changes=3, changed=['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'reg_alpha', 'reg_lambda', 'min_child_samples', 'subsample', 'colsample_bytree', 'feature_fraction_bynode']\n",
            "\n",
            "üîÑ ITERATION 33\n",
            "‚èπÔ∏è  Optimization halted by user\n",
            "üèÅ Final best configurations:\n",
            " ('GradientBoosting', '1d'): 0.7143  {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.1625, 'subsample': 0.8043, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            " ('GradientBoosting', '4h'): 0.6957  {'n_estimators': 75, 'max_depth': 9, 'learning_rate': 0.12, 'subsample': 0.85, 'min_samples_split': 12, 'min_samples_leaf': 1}\n",
            " ('LightGBM_Financial', '4h'): 0.6232  {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.1, 'n_estimators': 300, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_child_samples': 20, 'subsample': 0.8, 'colsample_bytree': 0.85, 'subsample_freq': 2, 'feature_fraction_bynode': 0.9, 'extra_trees': True}\n",
            "Results written to /content/drive/MyDrive/spy_prediction_models/brothaman.txt\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# STEP 5: ADAPTIVE HYPERPARAMETER SEARCH\n",
        "# ========================================\n",
        "print(\"üöÄ Starting adaptive optimization loop (Ctrl+C to stop) ‚Ä¶\")\n",
        "\n",
        "# Focused hyperparameter ranges per model/timeframe --------\n",
        "# Keep 1D GB conservative (fewer knobs) and 4H GB richer (more knobs)\n",
        "GB_1D_GRID={\n",
        "    'n_estimators':[100,120,150,180,200],\n",
        "    'max_depth':[3,4,5,6],\n",
        "    'learning_rate':[0.08,0.10,0.12,0.14,0.16,0.18],\n",
        "    'subsample':[0.75,0.8,0.85,0.9],\n",
        "    'min_samples_split':[2,5,8,10,12],\n",
        "    'min_samples_leaf':[1,2,3]\n",
        "}\n",
        "GB_4H_GRID={\n",
        "    'n_estimators':[40,50,60,75,100,150],\n",
        "    'max_depth':[6,7,8,9,10],\n",
        "    'learning_rate':[0.12,0.15,0.18,0.2,0.22],\n",
        "    'subsample':[0.7,0.8,0.85,0.9],\n",
        "    'min_samples_split':[2,5,8,10,12],\n",
        "    'min_samples_leaf':[1,2,3]\n",
        "}\n",
        "LGB_FIN_GRID={\n",
        "    'num_leaves':[31,40,50,60,70],\n",
        "    'max_depth':[6,8,10],\n",
        "    'learning_rate':[0.03,0.04,0.05,0.07,0.1],\n",
        "    'n_estimators':[150,200,250,300,400],\n",
        "    'reg_alpha':[0.0,0.001,0.01,0.1],\n",
        "    'reg_lambda':[0.0,0.001,0.01,0.1],\n",
        "    'min_child_samples':[10,15,20,30],\n",
        "    'subsample':[0.8,0.85,0.9],\n",
        "    'colsample_bytree':[0.8,0.85,0.9],\n",
        "    'subsample_freq':[1,2],\n",
        "    'feature_fraction_bynode':[0.7,0.8,0.9],\n",
        "    'extra_trees':[False, True]\n",
        "}\n",
        "\n",
        "def _jitter_value(base_val, choices, jitter_frac):\n",
        "    # For float-like grids, apply multiplicative jitter then clamp to range\n",
        "    lo, hi = min(choices), max(choices)\n",
        "    val = base_val * (1 + random.uniform(-jitter_frac, jitter_frac))\n",
        "    return float(min(max(val, lo), hi))\n",
        "\n",
        "def propose_params(\n",
        "    grid,\n",
        "    base=None,\n",
        "    max_param_changes=1,\n",
        "    exploration_prob=0.2,\n",
        "    jitter_frac=0.10,\n",
        "    param_weights=None,\n",
        "    param_jitters=None,\n",
        "):\n",
        "    \"\"\"Propose next params by changing at most N keys from base.\n",
        "\n",
        "    - If base is provided, start from base and mutate up to max_param_changes keys.\n",
        "    - With exploration_prob, draw a fully random sample instead.\n",
        "    - Floats receive small jitter; discrete pick neighbor/random from grid.\n",
        "    \"\"\"\n",
        "    # Exploration: fully random draw\n",
        "    if base is None or random.random() < exploration_prob:\n",
        "        return {k: random.choice(v) for k, v in grid.items()}\n",
        "\n",
        "    proposal = dict(base)\n",
        "    keys = list(grid.keys())\n",
        "    num_changes = max(1, min(max_param_changes, len(keys)))\n",
        "    # Choose which params to change using weights (direction-aware)\n",
        "    if param_weights:\n",
        "        w = np.array([max(0.001, float(param_weights.get(k, 1.0))) for k in keys], dtype=float)\n",
        "        if np.all(w == 0):\n",
        "            w = np.ones_like(w)\n",
        "        w = w / w.sum()\n",
        "        keys_to_change = list(np.random.choice(keys, size=num_changes, replace=False, p=w))\n",
        "    else:\n",
        "        keys_to_change = random.sample(keys, num_changes)\n",
        "\n",
        "    for k in keys_to_change:\n",
        "        choices = grid[k]\n",
        "        base_val = base.get(k, random.choice(choices))\n",
        "        # Determine if this looks like a float grid\n",
        "        if isinstance(choices[0], float) or isinstance(base_val, float):\n",
        "            this_jitter = jitter_frac\n",
        "            if param_jitters and k in param_jitters:\n",
        "                try:\n",
        "                    this_jitter = float(param_jitters[k])\n",
        "                except Exception:\n",
        "                    this_jitter = jitter_frac\n",
        "            proposal[k] = _jitter_value(float(base_val), choices, this_jitter)\n",
        "        else:\n",
        "            # Discrete/int: pick a nearby or different choice\n",
        "            if base_val in choices:\n",
        "                idx = choices.index(base_val)\n",
        "                candidates = [i for i in [idx-1, idx+1] if 0 <= i < len(choices)]\n",
        "                if candidates:\n",
        "                    proposal[k] = choices[random.choice(candidates)]\n",
        "                else:\n",
        "                    proposal[k] = random.choice(choices)\n",
        "            else:\n",
        "                proposal[k] = random.choice(choices)\n",
        "    return proposal\n",
        "\n",
        "# Prepare per-timeframe datasets and eval caches\n",
        "optimizer.prepare_datasets()\n",
        "\n",
        "# Save base models after initial dataset prep ---------------------------------\n",
        "try:\n",
        "    os.makedirs(os.path.join(MODEL_DIR, 'base models'), exist_ok=True)\n",
        "    base_dir = os.path.join(MODEL_DIR, 'base models')\n",
        "    # Train and save GB 1d\n",
        "    if '1d' in optimizer.train_data:\n",
        "        td1 = optimizer.train_data['1d']\n",
        "        gb1d_params = optimizer.best.get(('GradientBoosting','1d'),{}).get('params', {})\n",
        "        gb1d = GradientBoostingClassifier(random_state=42, **gb1d_params)\n",
        "        gb1d.fit(td1['X_tr'], td1['y_tr'], sample_weight=td1['sample_weight_tr'])\n",
        "        joblib.dump(gb1d, os.path.join(base_dir, 'gb_1d_base.joblib'))\n",
        "    # Train and save GB 4h\n",
        "    if '4h' in optimizer.train_data:\n",
        "        td4 = optimizer.train_data['4h']\n",
        "        gb4_params = optimizer.best.get(('GradientBoosting','4h'),{}).get('params', {})\n",
        "        gb4 = GradientBoostingClassifier(random_state=42, **gb4_params)\n",
        "        gb4.fit(td4['X_tr'], td4['y_tr'], sample_weight=td4['sample_weight_tr'])\n",
        "        joblib.dump(gb4, os.path.join(base_dir, 'gb_4h_base.joblib'))\n",
        "        # Train and save LGBM Financial 4h\n",
        "        lgb_params = optimizer.best.get(('LightGBM_Financial','4h'),{}).get('params', {})\n",
        "        lgb_fin_base = LGBMClassifier(\n",
        "            objective='binary', boosting_type='gbdt',\n",
        "            class_weight='balanced', random_state=42, verbose=-1,\n",
        "            device_type='gpu', gpu_device_id=0,\n",
        "            **lgb_params\n",
        "        )\n",
        "        # Train base LightGBM fully for the configured n_estimators (no early stopping)\n",
        "        lgb_fin_base.fit(\n",
        "            td4['X_tr'], td4['y_tr'],\n",
        "            sample_weight=td4['sample_weight_tr']\n",
        "        )\n",
        "        joblib.dump(lgb_fin_base, os.path.join(base_dir, 'lgb_fin_4h_base.joblib'))\n",
        "    print(\"‚úÖ Base models saved in 'base models' folder\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not save base models: {e}\")\n",
        "\n",
        "iteration=0\n",
        "tested_baselines=False\n",
        "try:\n",
        "    while True:\n",
        "        iteration+=1\n",
        "        print(f\"\\nüîÑ ITERATION {iteration}\")\n",
        "        # First pass: verify and log exact seeded bests so we reach them immediately\n",
        "        if not tested_baselines:\n",
        "            print(\"üß™ Baseline verification pass ‚Äì testing seeded best configurations exactly‚Ä¶\")\n",
        "            # ---------- GradientBoosting 1D (exact, with threshold calibration) ---------\n",
        "            gb_base = optimizer.best.get(('GradientBoosting','1d'),{}).get('params')\n",
        "            if gb_base and '1d' in optimizer.train_data:\n",
        "                td = optimizer.train_data['1d']\n",
        "                gb = GradientBoostingClassifier(random_state=42, **gb_base)\n",
        "                gb.fit(td['X_tr'], td['y_tr'], sample_weight=td['sample_weight_tr'])\n",
        "                if '1d' in optimizer.eval_cache:\n",
        "                    X_eval = optimizer.eval_cache['1d']['X']\n",
        "                    y_eval = optimizer.eval_cache['1d']['y']\n",
        "                    # Calibrate threshold on validation\n",
        "                    if len(td['X_val']) > 0:\n",
        "                        val_proba = gb.predict_proba(td['X_val'])[:, 1]\n",
        "                        best_thr = 0.5\n",
        "                        best_val_acc = accuracy_score(td['y_val'], (val_proba >= 0.5).astype(int))\n",
        "                        for thr in np.linspace(0.30, 0.70, 41):\n",
        "                            acc_thr = accuracy_score(td['y_val'], (val_proba >= thr).astype(int))\n",
        "                            if acc_thr > best_val_acc:\n",
        "                                best_val_acc = acc_thr\n",
        "                                best_thr = float(thr)\n",
        "                    else:\n",
        "                        best_thr = 0.5\n",
        "                        best_val_acc = float('nan')\n",
        "\n",
        "                    # REFIT on FULL in-sample (train + val) like the single script\n",
        "                    X_full = np.vstack([td['X_tr'], td['X_val']])\n",
        "                    y_full = np.hstack([td['y_tr'], td['y_val']])\n",
        "                    sw_full = compute_sample_weight('balanced', y_full)\n",
        "\n",
        "                    gb_full = GradientBoostingClassifier(random_state=42, **gb_base)\n",
        "                    gb_full.fit(X_full, y_full, sample_weight=sw_full)\n",
        "\n",
        "                    # Test @ best_thr and @0.50 for reference using the refitted model\n",
        "                    test_proba = gb_full.predict_proba(X_eval)[:, 1]\n",
        "                    test_acc_best = accuracy_score(y_eval, (test_proba >= best_thr).astype(int))\n",
        "                    test_acc_050  = accuracy_score(y_eval, (test_proba >= 0.50).astype(int))\n",
        "                    print(f\"   ‚Üí GB 1d baseline (REFIT full): val_acc@best_thr={best_val_acc:.4f}, thr={best_thr:.2f}, test_acc@best_thr={test_acc_best:.4f}, test_acc@0.50={test_acc_050:.4f}\")\n",
        "                    optimizer.log_best('GradientBoosting','1d',gb_base,test_acc_best)\n",
        "\n",
        "            # ---------- GradientBoosting 4H (exact) -------------------------\n",
        "            gb4_base = optimizer.best.get(('GradientBoosting','4h'),{}).get('params')\n",
        "            if gb4_base and '4h' in optimizer.train_data:\n",
        "                td4 = optimizer.train_data['4h']\n",
        "                gb4 = GradientBoostingClassifier(random_state=42, **gb4_base)\n",
        "                gb4.fit(td4['X_tr'], td4['y_tr'], sample_weight=td4['sample_weight_tr'])\n",
        "                if '4h' in optimizer.eval_cache:\n",
        "                    X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                    y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                    pred = gb4.predict(X_eval4)\n",
        "                    acc=accuracy_score(y_eval4,pred)\n",
        "                    optimizer.log_best('GradientBoosting','4h',gb4_base,acc)\n",
        "\n",
        "            # ---------- LightGBM_Financial 4H (exact, with threshold calibration) --------\n",
        "            lgb_base = optimizer.best.get(('LightGBM_Financial','4h'),{}).get('params')\n",
        "            if lgb_base and '4h' in optimizer.train_data:\n",
        "                td4 = optimizer.train_data['4h']\n",
        "                lgb_fin = LGBMClassifier(\n",
        "                    objective='binary', boosting_type='gbdt',\n",
        "                    class_weight='balanced', random_state=42, verbose=-1,\n",
        "                    device_type='gpu', gpu_device_id=0,\n",
        "                    **lgb_base\n",
        "                )\n",
        "                lgb_fin.fit(td4['X_tr'], td4['y_tr'])\n",
        "                if '4h' in optimizer.eval_cache:\n",
        "                    X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                    y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                    # Calibrate threshold on validation\n",
        "                    if len(td4['X_val']) > 0:\n",
        "                        val_proba = lgb_fin.predict_proba(td4['X_val'])[:, 1]\n",
        "                        best_thr = 0.5\n",
        "                        best_val_acc = accuracy_score(td4['y_val'], (val_proba >= 0.5).astype(int))\n",
        "                        for thr in np.linspace(0.30, 0.70, 41):\n",
        "                            acc_thr = accuracy_score(td4['y_val'], (val_proba >= thr).astype(int))\n",
        "                            if acc_thr > best_val_acc:\n",
        "                                best_val_acc = acc_thr\n",
        "                                best_thr = float(thr)\n",
        "                    else:\n",
        "                        best_thr = 0.5\n",
        "                        best_val_acc = float('nan')\n",
        "                    # Test @ best_thr and @0.50 for reference\n",
        "                    test_proba = lgb_fin.predict_proba(X_eval4)[:, 1]\n",
        "                    test_acc_best = accuracy_score(y_eval4, (test_proba >= best_thr).astype(int))\n",
        "                    test_acc_050 = accuracy_score(y_eval4, (test_proba >= 0.50).astype(int))\n",
        "                    print(f\"   ‚Üí LGB 4h baseline: val_acc@best_thr={best_val_acc:.4f}, thr={best_thr:.2f}, test_acc@best_thr={test_acc_best:.4f}, test_acc@0.50={test_acc_050:.4f}\")\n",
        "                    optimizer.log_best('LightGBM_Financial','4h',lgb_base,test_acc_best)\n",
        "\n",
        "            tested_baselines=True\n",
        "            # Proceed to next iteration after baseline verification\n",
        "            continue\n",
        "        # ---------- GradientBoosting 1D (with threshold calibration) -------\n",
        "        trials_1d = 2\n",
        "        for _ in range(trials_1d):\n",
        "            gb_base = optimizer.best.get(('GradientBoosting','1d'),{}).get('params')\n",
        "            # Every 20 iterations force one fully random exploration sample\n",
        "            force_random = (iteration % 20 == 0)\n",
        "            gb1d_weights = optimizer.get_param_weights('GradientBoosting','1d', GB_1D_GRID, default_jitter=0.08)\n",
        "            gb1d_jitters = optimizer.get_param_jitters('GradientBoosting','1d', GB_1D_GRID, default_jitter=0.08)\n",
        "            gb1d_explore, gb1d_changes = optimizer.current_search_hyperparams('GradientBoosting','1d', base_exploration=0.15, base_max_changes=1, grid=GB_1D_GRID, default_jitter=0.08)\n",
        "            gb_params = propose_params(\n",
        "                GB_1D_GRID, gb_base,\n",
        "                max_param_changes=gb1d_changes,\n",
        "                exploration_prob=(1.0 if force_random else gb1d_explore),\n",
        "                jitter_frac=0.08,\n",
        "                param_weights=gb1d_weights,\n",
        "                param_jitters=gb1d_jitters,\n",
        "            )\n",
        "            # Debug: what changed this trial\n",
        "            def _changed_keys(base, curr):\n",
        "                if not base:\n",
        "                    return list(curr.keys())\n",
        "                keys=[]\n",
        "                for k,v in curr.items():\n",
        "                    pv = base.get(k, None)\n",
        "                    if isinstance(v, float) or isinstance(pv, float):\n",
        "                        if not optimizer._nearly_equal(pv, v, tol=1e-8):\n",
        "                            keys.append(k)\n",
        "                    else:\n",
        "                        if pv != v:\n",
        "                            keys.append(k)\n",
        "                return keys\n",
        "            gb1d_changed = _changed_keys(gb_base, gb_params)\n",
        "            if '1d' not in optimizer.train_data:\n",
        "                break\n",
        "            td1 = optimizer.train_data['1d']\n",
        "            gb = GradientBoostingClassifier(random_state=42, **gb_params)\n",
        "            gb.fit(td1['X_tr'], td1['y_tr'], sample_weight=td1['sample_weight_tr'])\n",
        "            if '1d' in optimizer.eval_cache:\n",
        "                X_eval = optimizer.eval_cache['1d']['X']\n",
        "                y_eval = optimizer.eval_cache['1d']['y']\n",
        "                # Calibrate threshold on validation\n",
        "                if len(td1['X_val']) > 0:\n",
        "                    val_proba = gb.predict_proba(td1['X_val'])[:, 1]\n",
        "                    best_thr = 0.5\n",
        "                    best_val_acc = accuracy_score(td1['y_val'], (val_proba >= 0.5).astype(int))\n",
        "                    for thr in np.linspace(0.30, 0.70, 41):\n",
        "                        acc_thr = accuracy_score(td1['y_val'], (val_proba >= thr).astype(int))\n",
        "                        if acc_thr > best_val_acc:\n",
        "                            best_val_acc = acc_thr\n",
        "                            best_thr = float(thr)\n",
        "                else:\n",
        "                    best_thr = 0.5\n",
        "                    best_val_acc = float('nan')\n",
        "                # REFIT on FULL in-sample (train + val) like the single script\n",
        "                X_full = np.vstack([td1['X_tr'], td1['X_val']])\n",
        "                y_full = np.hstack([td1['y_tr'], td1['y_val']])\n",
        "                sw_full = compute_sample_weight('balanced', y_full)\n",
        "\n",
        "                gb_full = GradientBoostingClassifier(random_state=42, **gb_params)\n",
        "                gb_full.fit(X_full, y_full, sample_weight=sw_full)\n",
        "\n",
        "                # Test @ best_thr and @0.50 for reference using the refitted model\n",
        "                test_proba = gb_full.predict_proba(X_eval)[:, 1]\n",
        "                test_acc_best = accuracy_score(y_eval, (test_proba >= best_thr).astype(int))\n",
        "                test_acc_050  = accuracy_score(y_eval, (test_proba >= 0.50).astype(int))\n",
        "                print(f\"   ‚Üí GB 1d iter {iteration} (REFIT full): val_acc@best_thr={best_val_acc:.4f}, thr={best_thr:.2f}, test_acc@best_thr={test_acc_best:.4f}, test_acc@0.50={test_acc_050:.4f}, explore={gb1d_explore:.2f}, max_changes={gb1d_changes}, changed={gb1d_changed}\")\n",
        "                optimizer.log_best('GradientBoosting','1d',gb_params,test_acc_best)\n",
        "                optimizer.record_result('GradientBoosting','1d', GB_1D_GRID, gb_params, test_acc_best, base_exploration=0.15, base_max_changes=1, default_jitter=0.08)\n",
        "\n",
        "        # ---------- GradientBoosting 4H -----------------------------------\n",
        "        trials_4h = 3\n",
        "        for _ in range(trials_4h):\n",
        "            gb4_base = optimizer.best.get(('GradientBoosting','4h'),{}).get('params')\n",
        "            force_random = (iteration % 20 == 0)\n",
        "            gb4_weights = optimizer.get_param_weights('GradientBoosting','4h', GB_4H_GRID, default_jitter=0.10)\n",
        "            gb4_jitters = optimizer.get_param_jitters('GradientBoosting','4h', GB_4H_GRID, default_jitter=0.10)\n",
        "            gb4_explore, gb4_changes = optimizer.current_search_hyperparams('GradientBoosting','4h', base_exploration=0.20, base_max_changes=2, grid=GB_4H_GRID, default_jitter=0.10)\n",
        "            gb4_params = propose_params(\n",
        "                GB_4H_GRID, gb4_base,\n",
        "                max_param_changes=gb4_changes,\n",
        "                exploration_prob=(1.0 if force_random else gb4_explore),\n",
        "                jitter_frac=0.10,\n",
        "                param_weights=gb4_weights,\n",
        "                param_jitters=gb4_jitters,\n",
        "            )\n",
        "            # Debug: what changed this trial\n",
        "            gb4_changed = _changed_keys(gb4_base, gb4_params)\n",
        "            if '4h' not in optimizer.train_data:\n",
        "                break\n",
        "            td4 = optimizer.train_data['4h']\n",
        "            gb4 = GradientBoostingClassifier(random_state=42, **gb4_params)\n",
        "            gb4.fit(td4['X_tr'], td4['y_tr'], sample_weight=td4['sample_weight_tr'])\n",
        "            if '4h' in optimizer.eval_cache:\n",
        "                X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                pred = gb4.predict(X_eval4)\n",
        "                acc_4h_gb=accuracy_score(y_eval4,pred)\n",
        "                print(f\"   ‚Üí GB 4h iter {iteration}: acc={acc_4h_gb:.4f}, explore={gb4_explore:.2f}, max_changes={gb4_changes}, changed={gb4_changed}\")\n",
        "                optimizer.log_best('GradientBoosting','4h',gb4_params,acc_4h_gb)\n",
        "                optimizer.record_result('GradientBoosting','4h', GB_4H_GRID, gb4_params, acc_4h_gb, base_exploration=0.20, base_max_changes=2, default_jitter=0.10)\n",
        "\n",
        "        # ---------- LightGBM_Financial 4H (with threshold calibration) ------\n",
        "        trials_lgb = 3\n",
        "        for _ in range(trials_lgb):\n",
        "            lgb_base = optimizer.best.get(('LightGBM_Financial','4h'),{}).get('params')\n",
        "            force_random = (iteration % 20 == 0)\n",
        "            lgb_weights = optimizer.get_param_weights('LightGBM_Financial','4h', LGB_FIN_GRID, default_jitter=0.12)\n",
        "            lgb_jitters = optimizer.get_param_jitters('LightGBM_Financial','4h', LGB_FIN_GRID, default_jitter=0.12)\n",
        "            lgb_explore, lgb_changes = optimizer.current_search_hyperparams('LightGBM_Financial','4h', base_exploration=0.25, base_max_changes=2, grid=LGB_FIN_GRID, default_jitter=0.12)\n",
        "            lgb_params = propose_params(\n",
        "                LGB_FIN_GRID, lgb_base,\n",
        "                max_param_changes=lgb_changes,\n",
        "                exploration_prob=(1.0 if force_random else lgb_explore),\n",
        "                jitter_frac=0.12,\n",
        "                param_weights=lgb_weights,\n",
        "                param_jitters=lgb_jitters,\n",
        "            )\n",
        "            lgb_fin = LGBMClassifier(\n",
        "                objective='binary', boosting_type='gbdt',\n",
        "                class_weight='balanced', random_state=42, verbose=-1,\n",
        "                device_type='gpu', gpu_device_id=0,\n",
        "                **lgb_params\n",
        "            )\n",
        "            td4 = optimizer.train_data['4h'] if '4h' in optimizer.train_data else None\n",
        "            if td4 is None:\n",
        "                break\n",
        "            lgb_fin.fit(\n",
        "                td4['X_tr'], td4['y_tr'],\n",
        "                eval_set=[(td4['X_val'], td4['y_val'])],\n",
        "                eval_metric='auc',\n",
        "                callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
        "            )\n",
        "            if '4h' in optimizer.eval_cache:\n",
        "                X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                # Calibrate threshold on validation\n",
        "                if len(td4['X_val']) > 0:\n",
        "                    val_proba = lgb_fin.predict_proba(td4['X_val'])[:, 1]\n",
        "                    best_thr = 0.5\n",
        "                    best_val_acc = accuracy_score(td4['y_val'], (val_proba >= 0.5).astype(int))\n",
        "                    for thr in np.linspace(0.30, 0.70, 41):\n",
        "                        acc_thr = accuracy_score(td4['y_val'], (val_proba >= thr).astype(int))\n",
        "                        if acc_thr > best_val_acc:\n",
        "                            best_val_acc = acc_thr\n",
        "                            best_thr = float(thr)\n",
        "                else:\n",
        "                    best_thr = 0.5\n",
        "                    best_val_acc = float('nan')\n",
        "                # Test @ best_thr and @0.50 for reference\n",
        "                test_proba = lgb_fin.predict_proba(X_eval4)[:, 1]\n",
        "                test_acc_best = accuracy_score(y_eval4, (test_proba >= best_thr).astype(int))\n",
        "                test_acc_050 = accuracy_score(y_eval4, (test_proba >= 0.50).astype(int))\n",
        "                # Debug: what changed this trial (reuse helper)\n",
        "                lgb_changed = _changed_keys(lgb_base, lgb_params)\n",
        "                print(f\"   ‚Üí LGB 4h iter {iteration}: val_acc@best_thr={best_val_acc:.4f}, thr={best_thr:.2f}, test_acc@best_thr={test_acc_best:.4f}, test_acc@0.50={test_acc_050:.4f}, explore={lgb_explore:.2f}, max_changes={lgb_changes}, changed={lgb_changed}\")\n",
        "                optimizer.log_best('LightGBM_Financial','4h',lgb_params,test_acc_best)\n",
        "                optimizer.record_result('LightGBM_Financial','4h', LGB_FIN_GRID, lgb_params, test_acc_best, base_exploration=0.25, base_max_changes=2, default_jitter=0.12)\n",
        "\n",
        "        # Periodic Optuna kicks to refine local maxima using TS-CV\n",
        "        if iteration % 30 == 0:\n",
        "            try:\n",
        "                # GB 1d\n",
        "                if '1d' in optimizer.train_data:\n",
        "                    study = optimizer.get_study('GB_1d')\n",
        "                    base = optimizer.best.get(('GradientBoosting','1d'),{}).get('params')\n",
        "                    study.optimize(optimizer.optuna_objective_gb('1d', GB_1D_GRID, base), n_trials=25, n_jobs=1)\n",
        "                    best_params = study.best_params\n",
        "                    # Evaluate on test cache and log\n",
        "                    td1 = optimizer.train_data['1d']\n",
        "                    gb = GradientBoostingClassifier(random_state=42, **best_params)\n",
        "                    gb.fit(td1['X_tr'], td1['y_tr'], sample_weight=td1['sample_weight_tr'])\n",
        "\n",
        "                    # REFIT on FULL in-sample (train + val) like the single script\n",
        "                    X_full = np.vstack([td1['X_tr'], td1['X_val']])\n",
        "                    y_full = np.hstack([td1['y_tr'], td1['y_val']])\n",
        "                    sw_full = compute_sample_weight('balanced', y_full)\n",
        "\n",
        "                    gb_full = GradientBoostingClassifier(random_state=42, **best_params)\n",
        "                    gb_full.fit(X_full, y_full, sample_weight=sw_full)\n",
        "\n",
        "                    X_eval = optimizer.eval_cache['1d']['X']\n",
        "                    y_eval = optimizer.eval_cache['1d']['y']\n",
        "                    acc = accuracy_score(y_eval, gb_full.predict(X_eval))\n",
        "                    optimizer.log_best('GradientBoosting','1d', best_params, acc)\n",
        "                    # Feed Optuna importance back to direction-aware weights\n",
        "                    if get_param_importances is not None:\n",
        "                        try:\n",
        "                            importances = get_param_importances(study)\n",
        "                            for p, imp in importances.items():\n",
        "                                if p in optimizer.param_stats.get(('GradientBoosting','1d'), {}):\n",
        "                                    optimizer.param_stats[('GradientBoosting','1d')][p]['weight'] = max(0.1, min(5.0, 1.0 + 3.0*imp))\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                # GB 4h\n",
        "                if '4h' in optimizer.train_data:\n",
        "                    study = optimizer.get_study('GB_4h')\n",
        "                    base = optimizer.best.get(('GradientBoosting','4h'),{}).get('params')\n",
        "                    study.optimize(optimizer.optuna_objective_gb('4h', GB_4H_GRID, base), n_trials=30, n_jobs=1)\n",
        "                    best_params = study.best_params\n",
        "                    td4 = optimizer.train_data['4h']\n",
        "                    gb4 = GradientBoostingClassifier(random_state=42, **best_params)\n",
        "                    gb4.fit(td4['X_tr'], td4['y_tr'], sample_weight=td4['sample_weight_tr'])\n",
        "                    X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                    y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                    acc = accuracy_score(y_eval4, gb4.predict(X_eval4))\n",
        "                    optimizer.log_best('GradientBoosting','4h', best_params, acc)\n",
        "                    if get_param_importances is not None:\n",
        "                        try:\n",
        "                            importances = get_param_importances(study)\n",
        "                            for p, imp in importances.items():\n",
        "                                if p in optimizer.param_stats.get(('GradientBoosting','4h'), {}):\n",
        "                                    optimizer.param_stats[('GradientBoosting','4h')][p]['weight'] = max(0.1, min(5.0, 1.0 + 3.0*imp))\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                # LGB 4h\n",
        "                if '4h' in optimizer.train_data:\n",
        "                    study = optimizer.get_study('LGB_4h')\n",
        "                    base = optimizer.best.get(('LightGBM_Financial','4h'),{}).get('params')\n",
        "                    study.optimize(optimizer.optuna_objective_lgb('4h', LGB_FIN_GRID, base if base else {}), n_trials=35, n_jobs=1)\n",
        "                    best_params = study.best_params\n",
        "                    td4 = optimizer.train_data['4h']\n",
        "                    lgb_fin = lgb.LGBMClassifier(\n",
        "                        objective='binary', boosting_type='gbdt',\n",
        "                        class_weight='balanced', random_state=42, verbose=-1,\n",
        "                        device_type='gpu', gpu_device_id=0,\n",
        "                        **best_params\n",
        "                    )\n",
        "                    lgb_fin.fit(\n",
        "                        td4['X_tr'], td4['y_tr'],\n",
        "                        eval_set=[(td4['X_val'], td4['y_val'])],\n",
        "                        eval_metric='auc',\n",
        "                        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
        "                    )\n",
        "                    X_eval4 = optimizer.eval_cache['4h']['X']\n",
        "                    y_eval4 = optimizer.eval_cache['4h']['y']\n",
        "                    acc = accuracy_score(y_eval4, lgb_fin.predict(X_eval4))\n",
        "                    optimizer.log_best('LightGBM_Financial','4h', best_params, acc)\n",
        "                    if get_param_importances is not None:\n",
        "                        try:\n",
        "                            importances = get_param_importances(study)\n",
        "                            for p, imp in importances.items():\n",
        "                                if p in optimizer.param_stats.get(('LightGBM_Financial','4h'), {}):\n",
        "                                    optimizer.param_stats[('LightGBM_Financial','4h')][p]['weight'] = max(0.1, min(5.0, 1.0 + 3.0*imp))\n",
        "                        except Exception:\n",
        "                            pass\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Optuna phase warning: {e}\")\n",
        "\n",
        "        # Print status every iteration for the first 5, then every 5 thereafter\n",
        "        if iteration <= 5 or iteration % 5 == 0:\n",
        "            print(\"üìà Current bests:\")\n",
        "            for key,val in optimizer.best.items():\n",
        "                print(f\" {key}: {val['acc']:.4f}\")\n",
        "            # Brief direction-aware diagnostics\n",
        "            for tf in TIMEFRAMES_ORDERED:\n",
        "                for model_name, grid, dj, be, mc in [\n",
        "                    ('GradientBoosting', GB_1D_GRID if tf=='1d' else GB_4H_GRID, 0.08 if tf=='1d' else 0.10, 0.15 if tf=='1d' else 0.20, 1 if tf=='1d' else 2),\n",
        "                ]:\n",
        "                    w = optimizer.get_param_weights(model_name, tf, grid, dj)\n",
        "                    top = sorted(w.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "                    print(f\"   {model_name} {tf} focus ‚Üí {top}\")\n",
        "        time.sleep(1)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"‚èπÔ∏è  Optimization halted by user\")\n",
        "    print(\"üèÅ Final best configurations:\")\n",
        "    for key,val in optimizer.best.items():\n",
        "        print(f\" {key}: {val['acc']:.4f}  {val['params']}\")\n",
        "    print(f\"Results written to {TXT_RESULTS_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}